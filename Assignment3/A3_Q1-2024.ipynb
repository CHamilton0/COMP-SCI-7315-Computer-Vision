{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMOJD0_jdzzg",
    "tags": []
   },
   "source": [
    "# Computer Vision 2024 Assignment 3: Deep Learning for Perception Tasks\n",
    "\n",
    "This assignment contains 2 questions. The first question probes understanding of deep learning for classification. The second question is a more challenging classification experiment on a larger dataset. Answer the questions in separate Python notebooks.\n",
    "\n",
    "## Question 1: A simple classifier, 20 marks\n",
    "\n",
    "For this exercise, we provide demo code showing how to train a network on a small dataset called [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist). Please run through the code \"tutorial-style\" to get a sense of what it is doing. Then use the code alongside lecture notes and other resources to understand how to use pytorch libraries to implement, train and use a neural network.\n",
    "\n",
    "For the Fashion-MNIST dataset the lables from 0-9 correspond to various clothing classes so you might find it convenient to create a python list as follows:\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "You will need to answer various questions about the system, how it operates, the results of experiments with it and make modifications to it yourself. You can change the training scheme and the network structure. \n",
    "\n",
    "Organize your own text and code cell to show the answer of each questions.\n",
    "\n",
    "Detailed requirements:\n",
    "\n",
    "**Q1.1 (1 point)**\n",
    "\n",
    "Extract 3 images of different types of clothing from the training dataset, print out the size/shape of the training images, and display the three with their corresponding labels. \n",
    "\n",
    "**Q1.2 (2 points)** \n",
    "\n",
    "Run the training code for 10 epochs, for different values of the learning rate. Fill in the table below and plot the loss curves for each experiment:\n",
    "\n",
    "|Lr|Accuracy|\n",
    "|---|---|\n",
    "|1   |      |\n",
    "|0.1|          |\n",
    "|0.01|         |\n",
    "|0.001  |        |\n",
    "\n",
    "\n",
    "**Q1.3 (3 points)** \n",
    "\n",
    "Report the number of epochs when the accuracy reaches 85%. Fill in the table below and plot the loass curve for each experiment:\n",
    "\n",
    "|Lr|Accuracy|Epoch|\n",
    "|---|---|---|\n",
    "|1   |      |     |\n",
    "|0.1|          |    |\n",
    "|0.01|         |    |\n",
    "|0.001  |        |     |\n",
    "\n",
    "\n",
    "**Q1.4 (2 points)** \n",
    "\n",
    "Compare the results in table 1 and table 2, what is your observation and your understanding of learning rate?\n",
    "\n",
    "\n",
    "**Q1.5 (5 points)** \n",
    "\n",
    "Build a wider network by modifying the code that constructs the network so that the hidden layer(s) contain more perceptrons, and record the accuracy along with the number of trainable parameters in your model.  Now modify the oroginal network to be deeper instead of wider (i.e. by adding more hidden layers). Record your accuracy and network size findings. Plot the loss curve for each experiment. Write down your conclusions about changing the network structure?  \n",
    "\n",
    "|Structures|Accuracy|Parameters|\n",
    "|---|---|---|\n",
    "|Base   |      ||\n",
    "|Deeper|          ||\n",
    "|Wider|         ||\n",
    "\n",
    "\n",
    "**Q1.6 (2 points)** \n",
    "\n",
    "Calculate the mean of the gradients of the loss to all trainable parameters. Plot the gradients curve for the first 100 training steps. What are your observations? Note that this gradients will be saved with the training weight automatically after you call loss.backwards(). Hint: the mean of the gradients decrease.\n",
    "\n",
    "For more exlanation of q1.7, you could refer to the following simple instructions: https://colab.research.google.com/drive/1XAsyNegGSvMf3_B6MrsXht7-fHqtJ7OW?usp=sharing\n",
    "\n",
    "**Q1.7 (5 points)** \n",
    "\n",
    "Modify the network structure and training/test to use a small convolutional neural network instead of an MLP. Discuss your findings with rehgard to convergence, accuracy and number of parameters, relative to MLPs.  \n",
    "\n",
    "Hint: Look at the structure of the CNN in the Workshop 3 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-sqkIpLjpVsh"
   },
   "outputs": [],
   "source": [
    "import numpy as np # This is for mathematical operations\n",
    "\n",
    "# this is used in plotting \n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1wy3xhEx_x-1"
   },
   "outputs": [],
   "source": [
    "#### Tutorial Code\n",
    "####PyTorch has two primitives to work with data: torch.utils.data.DataLoader and torch.utils.data.Dataset. \n",
    "#####Dataset stores samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset.\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download training data from open datasets. \n",
    "##Every TorchVision Dataset includes two arguments: \n",
    "##transform and target_transform to modify the samples and labels respectively.\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNI4IusI_1ol",
    "tags": []
   },
   "source": [
    "**NOTE**: For consistency with the original data set, we call our validation data \"test_data\". It is important to keep in mind though that we are using the data for model validation and not for testing the final, trained model (which requires data not used when training the model parameters). \n",
    "\n",
    "We pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset and supports automatic batching, sampling, shuffling, and multiprocess data loading. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nQZ5l5Zs_4C3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9L1vl5rC52Un"
   },
   "source": [
    "Add in a code cell to inspect the training data, as per Q1.1. Each element of the training_data structure has a greyscale image (which you can use plt.imshow(img[0,:,:]) to display, just like you did in previous assignments.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_defs = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KpEhLSHg4Idw"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([28, 28])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATYUlEQVR4nO3dfazXdf3/8efxiIcDyIUEgkCHIXhBaJJGzCBMZegwd1Kj5R9qNtfMZnOrFmuBXckamGXatREtmSskEjWlTdj4w4Hm1SAvCKSJERceLtQTcOC8f3985/MngnJe77jo2/d229zi4+dx3u/PEbnz8RxeNVRVVQUARMRxx/oGAPjPIQoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAocM+vXr4+GhoaYM2fOYfuYy5Yti4aGhli2bNlh+5jH2nXXXRfDhw+vtR0+fHhcd911h/V++O8mChT59a9/HQ0NDfHkk08e61s5YhYvXhyTJk2KgQMHRo8ePWLEiBExbdq0eOSRR471rcERJwrwNnPmzInLL788GhoaYvr06XHHHXfElVdeGWvWrIn77rvvWN8eHHHHH+sbgP8Ue/fujW9/+9sxefLkWLJkyQF/f/PmzcfgruDo8k6Bw27Pnj0xY8aMOPfcc6NPnz7Rs2fPmDhxYixduvRdN3fccUe0tLREc3NzTJo0KVatWnXAc1544YW46qqr4qSTToru3bvHeeedFw888MAh76e9vT1eeOGF2Lp163s+b+vWrbFz58746Ec/etC/P3DgwOLX+Pavm/z85z+PU089NZqamuLDH/5wPPHEEwdcY9GiRTFmzJjo3r17jBkzJv7whz8c9F7mzJkT559/fvTv3z+am5vj3HPPjQULFhzqUwGHJAocdjt37oxf/vKXccEFF8T3vve9uPXWW2PLli0xZcqUeOaZZw54/m9+85u4884746abborp06fHqlWr4sILL4xNmzblc1avXh3jx4+P559/Pr72ta/F7bffHj179ozW1tZ3/YXzLStXrowzzzwz7rrrrvd83sCBA6O5uTkWL14cbW1th/U1zp8/P2bPnh2f//zn4zvf+U6sX78+rrjiiujo6MjnLFmyJK688spoaGiIWbNmRWtra3z2s5896NdvfvjDH8bYsWPjW9/6Vtx2221x/PHHx6c+9al46KGH3vO+4ZAqKDB37twqIqonnnjiXZ+zd+/eavfu3fs9tm3bturkk0+urr/++nzs5ZdfriKiam5urjZs2JCPr1ixooqI6pZbbsnHLrroouqss86qdu3alY91dnZW559/fjVq1Kh8bOnSpVVEVEuXLj3gsZkzZx7y9c2YMaOKiKpnz57VpZdeWn33u9+t/vKXv/zbr7F///5VW1tbPv7HP/6xiohq8eLF+dg555xTDR48uNq+fXs+tmTJkioiqpaWlv2u1d7evt+P9+zZU40ZM6a68MIL93u8paWluvbaaw/5uuEt3ilw2DU2NsYJJ5wQERGdnZ3R1tYWe/fujfPOOy+eeuqpA57f2toaQ4YMyR+PGzcuPvKRj8TDDz8cERFtbW3x2GOPxbRp0+L111+PrVu3xtatW+O1116LKVOmxJo1a+LVV1991/u54IILoqqquPXWWw9579/85jdj/vz5MXbs2Hj00Ufj61//epx77rnxoQ99KJ5//vnar/HTn/509OvXL388ceLEiIhYt25dRERs3Lgxnnnmmbj22mujT58++bzJkyfH6NGjD/h4zc3N+b+3bdsWO3bsiIkTJx702lBCFDgi5s2bF2effXZ07949+vfvHwMGDIiHHnooduzYccBzR40adcBjp512Wqxfvz4iIv72t79FVVXxjW98IwYMGLDfXzNnzoyIw/tF4M985jOxfPny2LZtWyxZsiSuvvrqePrpp+MTn/hE7Nq1q9ZrfP/737/fj98KxLZt2yIi4u9//3tEHPxzcfrppx/w2IMPPhjjx4+P7t27x0knnRQDBgyIn/zkJwe9NpTw3Uccdr/97W/juuuui9bW1vjKV74SAwcOjMbGxpg1a1asXbu2+ON1dnZGRMSXv/zlmDJlykGfM3LkyH/rng+md+/eMXny5Jg8eXJ069Yt5s2bFytWrIhJkyYVv8bGxsaDXqOq8f+Gu3z58rj88svjYx/7WPz4xz+OwYMHR7du3WLu3Lkxf/784o8HbycKHHYLFiyIESNGxMKFC6OhoSEff+t39e+0Zs2aAx576aWX8k/xjhgxIiIiunXrFhdffPHhv+EuOO+882LevHmxcePGiCh/jYfS0tISEQf/XLz44ov7/fj++++P7t27x6OPPhpNTU35+Ny5c2tdG97Ofz7isHvrd8Vv/13wihUr4vHHHz/o8xctWrTf1wRWrlwZK1asiEsvvTQi/ue7gi644IL42c9+lr8ov92WLVve8366+i2p7e3t73qPf/rTnyLi//+nnNLXeCiDBw+Oc845J+bNm7fffwL685//HH/961/3e25jY2M0NDTEvn378rH169fHokWLal0b3s47BWr51a9+ddBjH770pS/FZZddFgsXLoxPfvKTMXXq1Hj55Zfjpz/9aYwePTreeOONAzYjR46MCRMmxI033hi7d++OH/zgB9G/f//46le/ms+5++67Y8KECXHWWWfFDTfcECNGjIhNmzbF448/Hhs2bIhnn332Xe915cqV8fGPfzxmzpz5nl9sbm9vj/PPPz/Gjx8fl1xySQwbNiy2b98eixYtiuXLl0dra2uMHTs2IqL4NXbFrFmzYurUqTFhwoS4/vrro62tLX70ox/FBz7wgf0+5tSpU+P73/9+XHLJJXH11VfH5s2b4+67746RI0fGc889V+vakI7p9z7xv85b35L6bn+98sorVWdnZ3XbbbdVLS0tVVNTUzV27NjqwQcfrK699tr9vrXyrW/XnD17dnX77bdXw4YNq5qamqqJEydWzz777AHXXrt2bXXNNddUgwYNqrp161YNGTKkuuyyy6oFCxbkc/6db0nt6OiofvGLX1Stra157z169KjGjh1bzZ49e79vQa3zGt/pYPd0//33V2eeeWbV1NRUjR49ulq4cOEBH7Oqquqee+6pRo0aVTU1NVVnnHFGNXfu3GrmzJnVO/+V9i2plGqoqhpf6QLgv5KvKQCQRAGAJAoAJFEAIIkCAEkUAEhd/sNrb/+j/AD879OVP4HgnQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIA6fhjfQMcew0NDcWbqqqOwJ0cPjfffHPx5qmnnirebN68uXgzfvz44k1ExJYtW4o3zz33XPHm1VdfLd7wP6ZPn15rt3r16uLNAw88UOtah+KdAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkgPxiMbGxuLN3r17j8CdHNzFF19cvLnvvvuKN3UOnGttbS3efPCDHyzeRES0t7cXb77whS8Ub9atW1e8eeKJJ4o3Tz75ZPEmIuKFF14o3gwfPrx4c9FFFxVvWlpaijcREc3NzcUbB+IBcMSJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAaqiqqurSExsajvS98DbHHVev152dnYf5Tg7ujDPOKN5Mmzat1rWGDh1avHn99deLN9u3by/edHR0FG927dpVvImodwhhnYPWduzYUbzp379/8WbQoEHFm4iIzZs3F2/27dtXvPnd735XvLn66quLNxERp512WvHmmmuuKd505Zd77xQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJCOP9Y3cCzVOeTvaG3qHOBV1yWXXFK8ueWWW4o3d911V/EmImLt2rXFm9NPP73WtUqdfPLJxZsunkF5gB49ehRv3njjjeJNncMY//Wvfx2V60REvPnmm8Wb3//+98WbOodLDhs2rHgTEdGvX7/iTZ2DIrvCOwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACA5JbVQnZMT65wGWfeUzxdffLF4M2PGjOLN9ddfX7zp1atX8SYiYt26dcWbe++9t9a1/pP17du3eDNlypTizTnnnFO8GTFiRPGmzgmuEfVOzR0wYEDxps4JuHVOso2I2LNnT/HGKakAHHGiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQGqqqqrr0xBqHx9VR9zpdfBn/tnHjxhVv+vXrV7z54he/WLyJiHjssceKN/PmzSveDB8+vHgzf/784k1ExFVXXVW8WbVqVfHm+OPLz4fcu3dv8ea/0ZgxY4o3N910U61rdXR0FG+6detWvDnllFOKNyeccELxJiJi27ZtxZs777yzePP4448f8jneKQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIHX5BLDjjivvR51D6o7WwXYRETfeeGPxps5BcKtXry7eLFu2rHgTETF58uTizdKlS4s3EyZMKN48/PDDxZuIiDVr1tTalarzc6/OAY51f44fzWuVuvnmm4s3gwcPrnWtOgcX9urVq3jTp0+f4s327duLNxERb7zxRvHmH//4R61rHYp3CgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASF0+Waqzs/NI3scxsWHDhuLN008/Xbypc4DXSy+9VLyJiFi1alXxZtiwYcWbp556qngzdOjQ4k1ExO7du2vtSu3bt++oXKeuo3W43ZQpU4o3N9xwQ/HmkUceKd5ERIwaNap489prrxVv2tvbizc7duwo3kTU+7nnQDwAjjhRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABI5Se1/RcZN25c8aZv376H/0YOYtCgQbV2u3btKt6sX7++eDNkyJDizamnnlq8OZrqHFw4ePDg4k3v3r2LNxH1DhTs0aNH8abOP9srrriiePPKK68UbyIitm3bVrx58803izcdHR3Fmz179hRvIur9c9q7d2+tax2KdwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEBqqKqq6soTJ0yYUPzB65yc+M9//rN4ExGxffv24s373ve+o7Jpbm4u3vTq1at4U3fX2dlZvDnuuPLfT9Q5qTIi4t577y3e1DnxtM6pkz179ize1Pl8R9S7vzqndu7bt++obOqeOHziiScWb7p163ZUNnVOVo2IGDhwYPHmnnvuKd5s2rTpkM/xTgGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAKnLB+L169ev+INPmTKleHPKKacUbyIimpqaijddORzqnbr46dpP9+7dize9e/cu3kTUO7CvzueuzkFwdQ7Ri4gYNWpU8Wb9+vXFmzqvqc7Be3U1NDQcleucffbZxZsdO3YclU1EvX8H6xxuV8fq1atr7YYOHVq8+dznPle82bBhwyGf450CAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQBSlw/EO1qHcR1NjY2NxZs6h9vVOWitV69exZuIeofO1Tl8b/fu3cWbo3UoWURE3759izd1fo5v3LixeLNr167iTUS9w/d69OhRvKnzuavz71JHR0fxJiLixBNPLN7s27eveLNz587iTXt7e/EmomsH1b1TW1tb8aYrv9x7pwBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgPR/+kA8gP9LHIgHQBFRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKTju/rEqqqO5H0A8B/AOwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUA0v8DTIkuRPilXKwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([28, 28])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([28, 28])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code cell for training image display\n",
    "images, labels = next(iter(train_dataloader))\n",
    "\n",
    "import random\n",
    "training_indices = random.sample(range(batch_size), 3)\n",
    "\n",
    "training_images = [(images[index][0,:,:], labels[index]) for index in training_indices]\n",
    "\n",
    "for image in training_images:\n",
    "    plt.imshow(image[0], cmap=\"gray\")\n",
    "    plt.title(f\"Label: {label_defs[int(image[1])]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(f\"Shape: {image[0].shape}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMtCU2LO_9Dk"
   },
   "source": [
    "To define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the init function and specify how data will pass through the network in the forward function. To accelerate operations in the neural network, we move it to the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TRSp7pd3_6bS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "       )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nYAnKhOfABZr"
   },
   "outputs": [],
   "source": [
    "###Define the loss function and the optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFZYEHY7ADvS"
   },
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "L741B0uXAFrf"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        train_loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = train_loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return train_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A44xKKnjAINf"
   },
   "outputs": [],
   "source": [
    "##Define a test function\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "mJLACDm9AKxv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.293602  [    0/60000]\n",
      "loss: 2.286292  [ 6400/60000]\n",
      "loss: 2.264708  [12800/60000]\n",
      "loss: 2.256611  [19200/60000]\n",
      "loss: 2.249419  [25600/60000]\n",
      "loss: 2.218816  [32000/60000]\n",
      "loss: 2.220648  [38400/60000]\n",
      "loss: 2.191169  [44800/60000]\n",
      "loss: 2.187937  [51200/60000]\n",
      "loss: 2.151143  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.150740 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.158686  [    0/60000]\n",
      "loss: 2.154022  [ 6400/60000]\n",
      "loss: 2.090332  [12800/60000]\n",
      "loss: 2.101459  [19200/60000]\n",
      "loss: 2.062429  [25600/60000]\n",
      "loss: 2.000366  [32000/60000]\n",
      "loss: 2.021152  [38400/60000]\n",
      "loss: 1.947180  [44800/60000]\n",
      "loss: 1.947604  [51200/60000]\n",
      "loss: 1.867701  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 1.871943 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.904178  [    0/60000]\n",
      "loss: 1.880013  [ 6400/60000]\n",
      "loss: 1.752707  [12800/60000]\n",
      "loss: 1.791105  [19200/60000]\n",
      "loss: 1.692573  [25600/60000]\n",
      "loss: 1.637511  [32000/60000]\n",
      "loss: 1.664116  [38400/60000]\n",
      "loss: 1.565673  [44800/60000]\n",
      "loss: 1.588484  [51200/60000]\n",
      "loss: 1.478578  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 1.501884 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.564161  [    0/60000]\n",
      "loss: 1.536427  [ 6400/60000]\n",
      "loss: 1.380350  [12800/60000]\n",
      "loss: 1.455442  [19200/60000]\n",
      "loss: 1.343860  [25600/60000]\n",
      "loss: 1.329626  [32000/60000]\n",
      "loss: 1.354356  [38400/60000]\n",
      "loss: 1.279310  [44800/60000]\n",
      "loss: 1.309069  [51200/60000]\n",
      "loss: 1.206826  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.239128 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.308879  [    0/60000]\n",
      "loss: 1.297171  [ 6400/60000]\n",
      "loss: 1.129673  [12800/60000]\n",
      "loss: 1.236886  [19200/60000]\n",
      "loss: 1.118246  [25600/60000]\n",
      "loss: 1.130679  [32000/60000]\n",
      "loss: 1.163824  [38400/60000]\n",
      "loss: 1.101827  [44800/60000]\n",
      "loss: 1.133461  [51200/60000]\n",
      "loss: 1.048437  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.076165 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Train and test the model\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epochs with learning rate: 1\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.295444  [    0/60000]\n",
      "loss: 1.980232  [ 6400/60000]\n",
      "loss: 1.971453  [12800/60000]\n",
      "loss: 2.104311  [19200/60000]\n",
      "loss: 2.313797  [25600/60000]\n",
      "loss: 2.002636  [32000/60000]\n",
      "loss: 1.433282  [38400/60000]\n",
      "loss: 1.805757  [44800/60000]\n",
      "loss: 1.688983  [51200/60000]\n",
      "loss: 2.807741  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 13.4%, Avg loss: 1.820219 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.873500  [    0/60000]\n",
      "loss: 1.642794  [ 6400/60000]\n",
      "loss: 1.743324  [12800/60000]\n",
      "loss: 1.684400  [19200/60000]\n",
      "loss: 2.207927  [25600/60000]\n",
      "loss: 2.262850  [32000/60000]\n",
      "loss: 2.600851  [38400/60000]\n",
      "loss: 2.002929  [44800/60000]\n",
      "loss: 1.951202  [51200/60000]\n",
      "loss: 1.701331  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 20.4%, Avg loss: 1.715072 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.723304  [    0/60000]\n",
      "loss: 1.964605  [ 6400/60000]\n",
      "loss: 1.982199  [12800/60000]\n",
      "loss: 1.740803  [19200/60000]\n",
      "loss: 1.709157  [25600/60000]\n",
      "loss: 1.733052  [32000/60000]\n",
      "loss: 1.716095  [38400/60000]\n",
      "loss: 1.718857  [44800/60000]\n",
      "loss: 1.725096  [51200/60000]\n",
      "loss: 2.423784  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.3%, Avg loss: 2.306445 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.302557  [    0/60000]\n",
      "loss: 1.658897  [ 6400/60000]\n",
      "loss: 1.823656  [12800/60000]\n",
      "loss: 1.842475  [19200/60000]\n",
      "loss: 1.635962  [25600/60000]\n",
      "loss: 2.305983  [32000/60000]\n",
      "loss: 2.305836  [38400/60000]\n",
      "loss: 2.288764  [44800/60000]\n",
      "loss: 2.300480  [51200/60000]\n",
      "loss: 2.330135  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305386 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.258938  [ 6400/60000]\n",
      "loss: 1.869313  [12800/60000]\n",
      "loss: 1.765106  [19200/60000]\n",
      "loss: 1.701100  [25600/60000]\n",
      "loss: 1.827514  [32000/60000]\n",
      "loss: 1.711459  [38400/60000]\n",
      "loss: 1.770314  [44800/60000]\n",
      "loss: 1.675824  [51200/60000]\n",
      "loss: 1.700645  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 1.748068 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.820141  [    0/60000]\n",
      "loss: 1.696529  [ 6400/60000]\n",
      "loss: 2.377900  [12800/60000]\n",
      "loss: 2.353431  [19200/60000]\n",
      "loss: 2.248964  [25600/60000]\n",
      "loss: 2.340158  [32000/60000]\n",
      "loss: 2.333593  [38400/60000]\n",
      "loss: 2.298752  [44800/60000]\n",
      "loss: 1.760818  [51200/60000]\n",
      "loss: 1.723988  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 20.0%, Avg loss: 1.717382 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.717674  [    0/60000]\n",
      "loss: 2.018455  [ 6400/60000]\n",
      "loss: 2.382229  [12800/60000]\n",
      "loss: 2.308788  [19200/60000]\n",
      "loss: 2.281777  [25600/60000]\n",
      "loss: 2.303618  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.370693  [25600/60000]\n",
      "loss: 2.304783  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRSElEQVR4nO3deViU57k/8O+wowwgKggCgrgALohbGm2MJkZjjK1dctI0jTFJe9JTTGNt0xPTX9rTk4XYk7TJaVJ7spo08Zi2ibExq41Rs3lccQMRUIQooEYFBFnn/f1x884CM8PMMDPvzLzfz3Vx8Q4M8CQ4w3fu536ex6AoigIiIiIijYRpPQAiIiLSN4YRIiIi0hTDCBEREWmKYYSIiIg0xTBCREREmmIYISIiIk0xjBAREZGmGEaIiIhIUxFaD8AVJpMJp0+fhtFohMFg0Ho4RERE5AJFUdDc3Iy0tDSEhTmufwRFGDl9+jQyMjK0HgYRERF5oLa2Funp6Q4/HxRhxGg0ApD/mPj4eI1HQ0RERK5oampCRkaG+e+4I0ERRtSpmfj4eIYRIiKiINNfiwUbWImIiEhTDCNERESkKYYRIiIi0hTDCBEREWmKYYSIiIg0xTBCREREmmIYISIiIk0xjBAREZGmGEaIiIhIUwwjREREpCmGESIiItIUwwgRERFpimGEAkdTE/DYY0BFhdYjISIiP2IYocDx3HPA6tXArFnAwYNaj4aIiPyEYYQCx/798v7cOeCaa4ADB7QdDxER+QXDCAWOI0fk/dChwFdfAddeC5SUaDokIiLyPYYRCgzd3UBZmVx/8AEwc6YlkKgVEyIiCkkMIxQYqqqA9nYgNhYoLAQ+/BC44grg/HkJJPv2aT1CIiLyEYYRCgzqFE1+PhAWBiQkSCD52teACxeA+fOBvXu1HSMREfkEwwgFhsOH5f2ECZaPxcfLlM2VV1oCyZ492oyPiIh8xq0wUlxcjBkzZsBoNCI5ORlLly5FeXm5y1+/YcMGGAwGLF261N1xUqhTKyPWYQSwBJLZs4GLFyWQ7N7t9+EREZHvuBVGtm/fjqKiIuzcuRNbtmxBZ2cnFixYgJaWln6/trq6Gr/4xS9w1VVXeTxYCmFqGJk4se/njEbgvfeAr38daGyUQLJrl3/HR0REPmNQFEXx9IvPnj2L5ORkbN++HXPmzHF4v+7ubsyZMwd33nknPvnkE1y8eBFvvfWWyz+nqakJCQkJaGxsRHx8vKfDpUDV2QkMHizvq6uBUaPs36+5GVi8GPjkE6mYqE2uREQUkFz9+z2gnpHGxkYAQFJSktP7/ed//ieSk5Nx1113ufR929vb0dTUZPNGIayiQoJIXByQmen4fkYj8O67wJw5snX8ddcBX3zhv3ESEZFPeBxGTCYTVq5cidmzZ2OivdJ6j08//RQvvPACnnvuOZe/d3FxMRISEsxvGRkZng6TgoF186rB4Py+cXESSK6+WiolCxcCn3/u+zESEZHPeBxGioqKcPjwYWzYsMHhfZqbm3Hbbbfhueeew7Bhw1z+3qtXr0ZjY6P5rba21tNhUjBw1LzqyODBwDvvAHPnWgLJZ5/5bHhERORbEZ580YoVK7B582bs2LED6enpDu9XVVWF6upqLFmyxPwxk8kkPzgiAuXl5cjJyenzddHR0YiOjvZkaBSMnDWvOqIGkiVLgK1bgeuvtzS5EhFRUHGrMqIoClasWIGNGzdi69atyM7Odnr/3NxcHDp0CCUlJea3b3zjG5g3bx5KSko4/ULC3h4jrhg0CHj7bdmh9dIlCSSffOL98RERkU+5VRkpKirC+vXrsWnTJhiNRtTX1wMAEhISEBsbCwBYtmwZRo4cieLiYsTExPTpJ0lMTAQAp30mpCNtbUBlpVx78m9CDSTf+Abwz38CixZZmlyJiCgouFUZWbt2LRobGzF37lykpqaa315//XXzfWpqalBXV+f1gVKIKi+XQ/ISE4HUVM++R2ws8I9/yOqalhYJJNu3e3WYRETkO25VRlzZkmTbtm1OP79u3Tp3fiSFOuvm1f5W0jgTGwts2gR861uyY+sNNwCbNwPz5nlnnERE5DM8m4a05UnzqiOxscBbb0nvSGurbJC2devAvy8REfkUwwhpy9PmVUdiYoCNG2Wq5vJl4MYbgY8+8s73JiIin2AYIW15szKiUgPJ4sWWQPLPf3rv+xMRkVcxjJB2WluB48fl2luVEVV0NPDGGxJE2tpkP5IPP/TuzyAiIq9gGCHtlJUBigIMGwYkJ3v/+0dHA3//uwSRtjZZ/vvBB97/OURENCAMI6QdX0zR9KYGkm9+E2hvl/fvv++7n0dERG5jGCHteLt51ZGoKOCvfwWWLrUEknff9e3PJCIilzGMkHb8URlRqYHkW98COjrk/Tvv+P7nEhFRvxhGSDv+qoyoIiOB118HvvMdCSTf/rZsjEZERJpiGCFtNDcDNTVy7a8wAkgg+d//Bb77XUsgeftt//18IiLqg2GEtFFaKu9TU4GkJP/+7MhIYP164KabgM5OqZRs2uTfMRARkRnDCGnD31M0vamB5OabJZDcdJNsJU9ERH7HMELasD4gTysREcCrrwLf+54lkGzcqN14iIh0imGEtOHPlTTOREQAf/kL8P3vA11dwL/8i+zcSkREfsMwQtrQeprGWkQE8MorwK23SiC5+WbZKI2IiPyCYYT878IF4PRpuQ6EMAIA4eHAyy8Dt90GdHfL1M3f/qb1qIiIdIFhhPxPnaLJyADi47Udi7XwcOCll4BlyySQ3HKL7EtCREQ+xTBC/hcIzauOhIcDL74ILF8ugeT73wc2bNB6VEREIY1hhPwvUJpXHQkPB55/HrjjDsBkkl6S9eu1HhURUchiGCH/C6TmVUfUQHLXXRJIbrsNeO01rUdFRBSSGEbI/wK9MqIKCwOefRb44Q8lkCxbJsuAiYjIqxhGyL/OngXOnJHrvDxtx+KKsDDgf/4H+NGPJJDcfrssAyYiIq9hGCH/Uqsi2dnA4MHajsVVYWHAn/8M3H03oCjS3Pryy1qPiogoZDCMkH8FyxRNb2FhwJ/+BPzbv0kgueMOWQZMREQDxjBC/hUMzauOhIUBzzwD/OQnEkjuukuWARMR0YAwjJB/BWtlRGUwAE8/DaxYYQkkzz+v9aiIiIIawwj5j6IEd2VEZTAA//3fwE9/Krd/9CNZdUNERB5hGCH/qa+Xc2nCwoDcXK1HMzAGA/Dkk8C998rtu++WVTdEROQ2hhHyH3WKZswYICZG27F4g8EA/OEPwMqVcvvHPwbWrtV0SEREwYhhhPwnFKZoejMYgN//Hli1Sm7/5Cey6oaIiFzGMEL+E+zNq44YDMDjjwO/+IXcLiqSJlciInJJhNYDIB0JxcqIymAAfvc7ef9f/wXccw9gNMqOrUTect99wLZtWo+CQtUjjwALFmjyoxlGyD8UBSgtletQDCOABJE1a4Dubpm6+cMfGEbIe2pqpAJH5Cvnz2v2oxlGyD++/BJoagIiIoBx47Qeje8YDLLC5ve/l2mptrbQaNYl7e3aJe9zc4EnntB2LBSapkzR7EczjJB/qFM048YBUVHajsXXMjKAYcOAc+eAgweBmTO1HhGFgt275f3cucANN2g6FCJvYwMr+UeoNq/aYzAA06bJ9d692o6FQodaGZkxQ9txEPkAKyPkHy40r5pM8uKvqUn2RQsP7/ve3scG8rmwMMkOXjd9OvDBBwwj5B3d3ZZ/S6y0UQhyK4wUFxfjzTffxNGjRxEbG4tZs2ZhzZo1GD9+vMOvefPNN/Hoo4+isrISnZ2dGDt2LH7+85/jtttuG/DgKYiolREnYWTDBuDWW/00HitqKHE1xLgSeqIvrcQvcQBL9uzx/38QhZ7ycpiaL+G6sI/x8eQQbQAnza1fD3zve9r8bLfCyPbt21FUVIQZM2agq6sLDzzwABYsWIDS0lIMHjzY7tckJSXhV7/6FXJzcxEVFYXNmzfjjjvuQHJyMhYuXOiV/wgKcCaTZSWNk2ma7dvlfWqqtFx0d8ubyWT73t7HHH1OUVwbnskEdHV54b/VbBgu4zdYcuRKNrHSwO3ejSrkYKtprtYjIfIJg6K48nRt39mzZ5GcnIzt27djzpw5Ln/d1KlTsXjxYjz00EMu3b+pqQkJCQlobGxEfHy8p8MlrRw/DuTkSONqS4usqLFj1izgiy+kQnLzzd750YriXnjxRgA6cwZYvhyIQjsuIQ6R//cZS+s0MCtW4I1n6vBdvIEpU4D339d6QBSKEhK8/7rJ1b/fA+oZaWxsBCDVD1coioKtW7eivLwca9ascXi/9vZ2tLe3m283NTUNZJikNXWKJi/PYRAxmYBDh+R60iTv/WiDweGP9BmTSQ70bWqKxlHkYtKePQwjNDC7duEgFgMACguBlBSNx0PkZR6vpjGZTFi5ciVmz56Nif2skGhsbERcXByioqKwePFi/PGPf8R1113n8P7FxcVISEgwv2VkZHg6TAoELvSLVFcDly5J8STYtyEJC7Ms19+PQjax0sB0dAAHDuAgJgMAJk/WeDxEPuBxGCkqKsLhw4exYcOGfu9rNBpRUlKC3bt345FHHsGqVauwzcmWxqtXr0ZjY6P5rba21tNhUiBwYSWNWhWZMMH/lQxfUMNICaYwjNDAHDwIdHTgUFgBAIYRCk0ePe2vWLECmzdvxo4dO5Cent7v/cPCwjBmzBgAwJQpU1BWVobi4mLMnTvX7v2jo6MRHR3tydAoELmwx8jBg/I+VJ5oCwvl/X4UAod/CVy+DMTGajsoCk67duESBqPKNBqAd6cxiQKFW5URRVGwYsUKbNy4EVu3bkV2drZHP9RkMtn0hFAI6+4Gysrk2kllRA0jofJEa66MGAqhdHdb/gOJ3LV7Nw5DgnxqKjB8uMbjIfIBtyojRUVFWL9+PTZt2gSj0Yj6+noAQEJCAmJ7XvUtW7YMI0eORHFxMQDp/5g+fTpycnLQ3t6Od999F3/5y1+wdu1aL/+nUECqqgLa26Uq4CS8qtM0oVIZyc8HIiOBi52JOIlRyNq7F7jiCq2HRcFo1y4cxGwAofP4IOrNrTCiBoje0ysvvfQSli9fDgCoqalBWJil4NLS0oKf/OQn+PLLLxEbG4vc3Fy8+uqruNlbazcpsKlTNPn50tlpR2srUFEh16HyZBsVJYWgkhLpG8li3wh5orkZKCvDQfwbgNB5fBD15lYYcWVLkt6NqQ8//DAefvhhtwZFIcSF5tXSUlkOO3x4aC1ZLCyUMLIfhVi6502th0PBaN8+QFFwMHoG0M4wQqGLB+WRb+mweVVls6LmyBFpYiVyx65dUAAcNMnjJ9QeI0QqhhHyLTeW9YbaE615RU3YNGnkZRMruWv3btQiA42dgxERAeTmaj0gIt9gGCHf6ewEjh2Tax2tpFEVyLYQqDWl4yskATw0j9y1e7d5s7PcXOlFIgpFDCPkOxUVEkji4oDMTLt3UZTQnaaJj5cjeQBufkYeOHsWqK7GQXCzMwp9DCPkO9ZTNAaD3bs0NADnzslCm/x8P47NT7gTK3ls924AwMF4Luul0McwQr7jRvPq2LGhuUGpzU6sbGIld+zaBQA4ZGBlhEIfwwj5jgvNq6E6RaMyV0bCp0sT64EDmo6Hgsju3WhDNMqbUwGE7mOECGAYIV9y4bTeUF1Jo1IrI0dNY3EZMZyqIdcoCrB7N8qQh25TGJKSgLQ0rQdF5DsMI+QbbW1AZaVcuzBNE2oraVTqWSLdSricL8IwQq44eRI4exYHw6cCkLDuoO2KKCQwjJBvlJfLtERiovxFtqOzU3ZfBUK3MmIw9Oob4fJecoXavDp0HoDQfXwQqRhGyDesm1cdvKSrqAA6OgCjERg1yo9j8zObFTWlpWxipf6pYSRqGgCGEQp9DCPkG240r06a5PAMvZBgroxEzGQTK7mmZyXNwaYsAAwjFPpC+E8AacqF5tVQ7xdRqZWRg8pEdCOMUzXkXHc3sHcvGpCMM02xMBicPoyIQgLDCPmGjg/I623sWGDQIKC1OwYVGMsmVnLu6FHg0iUcjJkJABgzRv79EIUyhhHyvtZW4Phxudbxsl5VeLjlv5E7sVK/1H6RtOsBhP7jgwhgGCFfKCuTfRKGDweSk+3e5eJFoKZGrp0UT0KGOlWzH4XSxNraqul4KICpYSTmCgAMI6QPDCPkfS40r6pVkcxMWf0b6tQm1pIoNrFSP9Tm1VY5ZZFhhPSAYYS8jzuv9mFdGVEATtWQfe3twIED6EI4Sk8nAtDPY4T0jWGEvM+N5tVQX0mjUpcvn+1IRB1SGUbIvoMHgc5OHEu8Ah0dBsTFAVlZWg+KyPcYRsj7eEBeH7GxQG6uXJdgCpf3kn3qFM2oJQBCfw8eIhX/mZN3NTdbOlMdhBGTyZJX9BJGgF7bwrOJlexRm1eNswHo6/FB+sYwQt6lHjaTmgokJdm9y8mTklmiomQPDr0wbwsf/TVJZGxipd7Uykj7OAAMI6QfDCPkXW5M0eTnA5GRfhhTgDBXRsLlvBH2jZCN5mbZ8AzAwdPDADCMkH4wjJB3udC8qreVNCq1MlLVmoYmGNk3Qrb27gUUBRfSJ6H2VDgA/TR4EzGMkHe5eUCengwdCmRkyPUBFLAyQrZ6pmgO5SwFICdZJyRoOB4iP2IYIe/imTROmftGMIVNrGRLbV5NvAqA/sI66RvDCHnPhQvA6dNynZ9v9y6XLwMVFXKtxzBi7huJnSVNrCUlmo6HAogaRrqkqqjHxwfpF8MIeY9aFcnIAOLj7d6ltFT+Bg8fDqSk+HFsAcJcGYmcIRecqiEAOHNGlpkZDDjYIA8MhhHSE4YR8h43d141GPwwpgCjVkYOX8pCByIZRkj0VEVM4/NwuEyaVxlGSE8YRsh7uPNqv0aNkoMBO00RKEMeV9SQ6GlePZF3A1pagOhofe3BQ8QwQt7DZb39MhhsD81DWRnQ0qLpmCgAqP0iw+YBkDwfEaHlgIj8i2GEvKef03oVxbLpqJ5XCpj7RgbN5k6sJA8MNYygAIB+wzrpF8MIecfZs9KEBwB5eXbv0tAAnDsnB385WGyjC+YVNTFXygX7RvStuloeGJGROHh2BACGEdIfhhHyDrUqMno0MHiw3buoUzRjxwKDBvlpXAHIXBlpGQMFYN+I3vVURVBQgIOH2bxK+sQwQt7BnVddlpcnhwQ2tcfgBLJZGdG7nubVS4VXoapKPsQwQnrDMELe0U+/CMCVNKrISEuPbwmmsIlV73oqI0dSroGiACNGyD48RHriVhgpLi7GjBkzYDQakZycjKVLl6K8vNzp1zz33HO46qqrMGTIEAwZMgTz58/Hrp5XAhRCuJLGLea+kbiruBOrnnV3mytjByOmAuDjg/TJrTCyfft2FBUVYefOndiyZQs6OzuxYMECtDh5Vbdt2zbccsst+Pjjj/HFF18gIyMDCxYswKlTpwY8eAoQitLvNE1XlyWv6H2aBui1ogbgVI1eqVWxuDg2r5KuubWS/f3337e5vW7dOiQnJ2Pv3r2YM2eO3a957bXXbG4///zzeOONN/DRRx9h2bJlbg6XAlJ9vZxLExYG5ObavcuxY0BHBxAXB2Rl+Xd4gchcGbnc8/+LYUSf1ObVadNw8JC8NmRYJz0a0LY6jY2NAICkpCSXv6a1tRWdnZ1Ov6a9vR3t7e3m201NTZ4PknxPrYqMGQPExNi9i3Xzahg7lTB5smyAdqo5HmcxDMMZRvSpJ4woM2bi4PPyIVZGSI88/rNgMpmwcuVKzJ49GxOd9An09u///u9IS0vD/PnzHd6nuLgYCQkJ5reMjAxPh0n+4ELzKvtFbBmNkt0ANrHqWk//3KmcObh4EQgPd7hND1FI8ziMFBUV4fDhw9iwYYPLX/PYY49hw4YN2LhxI2IcvIIGgNWrV6OxsdH8Vltb6+kwyR/cPCCPhLlvxDiHTax61NZmfmAcjJZTnHNz5VwaIr3xKIysWLECmzdvxscff4z09HSXvubxxx/HY489hg8//BCT+3l5HB0djfj4eJs3CmA8IM8j5jNq4nv6rThVoy8HDgCdncDw4ThYnwyAjw/SL7d6RhRFwT333IONGzdi27ZtyM7Odunrfve73+GRRx7BBx98gOnTp3s0UApQitJvZaSxEaipkWtWRizUJtaS9p698bkTq76ozaszZuDgIQMAhhHSL7cqI0VFRXj11Vexfv16GI1G1NfXo76+HpcvXzbfZ9myZVi9erX59po1a/Dggw/ixRdfRFZWlvlrLl265L3/CtJObS3Q3CxHjDo481ztF8nIABIT/Te0QKdWRsrPD0MrYlkZ0RvrMMLKIemcW2Fk7dq1aGxsxNy5c5Gammp+e/311833qampQV1dnc3XdHR04Lvf/a7N1zz++OPe+68g7ahVkXHjZI9zO/hEa19qKpCSAphMBhzCJODoUYAhXT96mlfbC7+Go0flQ3yMkF65PU3Tn23bttncrq6ududHULDhzqsDMmUK8MEHwP6EebiicZc0sX7961oPi3ytqQno2b26zDgT3d3AkCHAyJEaj4tII9zxgQaGB+QNiLlvJPFqueBUjT7s3Sv9VllZOPil7Lmk7j1DpEcMIzQw/VRGFIWVEWfMK2q6epIaw4g+qOdzsV+ECADDCA2EyQSUlsq1g8rIyZPS3xoVJW0lZEutjBw8m4ouhDOM6AWbV4lsMIyQ56qrgdZWSRo5OXbvoj7R5uUBkZH+G1qwGDMGGDwYaOsIRwXGyk6sbGINfWplZOZMTmMSgWGEBkKdosnLk6W9dvBVn3NhYUBBgVzvT7xG5rW4E2toa2iQJfEGA85kTENDg/SKOGm7Igp5DCPkOe686hXmbeGHXisXnKoJbeoUTV4eDp2IAyCFxbg4DcdEpDGGEfKcG8t6WYJ2TO0b2a9MkQvuxBra7EzRMKyT3jGMkOf6Oa338mXg2DG55pOtY+bKyLmRUABWRkIdm1eJ+mAYIc90d0uzJeAwjJSWyoKbYcOAESP8OLYgM3GiHB1/rikapzCSO7GGMkWxhBFWRojMGEbIM1VVQHs7EBsLODgw0Xp/EW7m5FhMjPQAA0BJ0rVsYg1lJ04AX30FREWhK3+yubjIMEJ6xzBCnlGbV/PzZUmIHVyy6Dpz38jwBXLBvpHQpFZFCgpQcTIK7e2ytNvFA9CJQhbDCHnGheZVlqBdZ+4bCZsqF+wbCU0O9hdxkOeJdIMPAfJMP82rALeBd4e5MnJ+lFwwjIQmNq8S2cUwQp7pZ4+RhgbgzBnpFcnP9+O4gpS68dmJhkG4iARpYm1u1nZQ5F1dXZaQyTBCZINhhNzX0WE+/tzRNI36RDt2LDBokJ/GFcSSkoBRPUWRA8Pms4k1FJWVyfEJRiMwfjzDCJEVhhFyX0WFvMozGoGMDLt34RSN+8x9IyMWygWnakKLOkUzbRouNoejpkZuOmm7ItINhhFyn3W/iIM1u1xJ4z5z30jETLngiprQYrW/iDrLmZEBDBmi3ZCIAgXDCLnPheZVlqDdZ66MNPas82RlJLSoK2nYL0LUB8MIua+f5tWuLtl9FeCTrTvUysiRWiPaESV9OWxiDQ1tbZaEzjBC1AfDCLmvnz1GKipg3swpK8t/wwp2asm+q8uA0uR5bGINJSUlktKTk4HMTIYRol4YRsg9bW2SNgCHlRFu5uQZg8GqbyRtsVywbyQ0WO0vYlIMbPAm6oV/Ksg95eVy+t2QIUBqqt278FWf58x9I9FXyAX7RkKDVRiprpZzEKOigHHjNB0VUcBgGCH3uLCShq/6PGeujFwaIxcMI6HBzjbwEyYAERHaDYkokDCMkHv6aV4FuKx3INTKyIGTiTDBwCbWUNDYaNkkkM2rRHYxjJB7+mlebWwETp6Ua4YR940fD0RHA82XwnB8xGxpYt2/X+th0UCo1a3sbGDYMIYRIjsYRsg9/VRGuJnTwERGWkJcScaNcsGpmuBmtb8IwJ4qInsYRsh1ra3AiRNy7cJKGvKMOlWzP3a2XDCMBDer5tWWFqCyUm4yjBBZMIyQ68rKZNpg+HDZL8EOvuobOLWJteRyz1ILLu8NblbNq0eOyEMoOdnhQ4hIlxhGyHUuNK9yJc3AmSsjNUPl4tgxNrEGq/p64MsvZcOdqVP5+CBygGGEXNdP86qicJrGGyZPllXTdQ3haEgrZBNrMFOnaPLygLg4Vg6JHGAYIdf1Uxk5eVJewEdGyqoQ8kxcHDB2rFyXjPqmXHCqJjhZTdEAnMYkcoRhhFzXz2m96hNtfr4EEvKcuW8k7utywSbW4GTVvGpdOWQYIbLFMEKuaWoCamrk2kEYUefDOUUzcOa+kfZ8uWAYCT6KYgkjM2fi9Gng/HkgPFxmbYjIgmGEXFNaKu9TU4GkJLt34as+7zFXRk4Pl4vycgmEFDyOH5f0ERUFTJpkfnyMHw/ExGg7NKJAwzBCrumneRVgGPEmtTJyrCoCLSN7lviyiTW4qFWRKVOAqCg+PoicYBgh1/TTL9LWJitQAU7TeENKihShFAU4mPMt+SCnaoILm1eJXMYwQq7pZyVNaSlgMgFDh8ofURo4tTpSknC1XDCMBBer5lWAYYTIGbfCSHFxMWbMmAGj0Yjk5GQsXboU5epplA4cOXIE3/nOd5CVlQWDwYAnn3xyIOMlrfQzTWP9RGsw+GlMIU7tG9nf2fP/nMt7g0dXF7Bvn1zPmIH2duDoUbnJMELUl1thZPv27SgqKsLOnTuxZcsWdHZ2YsGCBWhpaXH4Na2trRg9ejQee+wxjBgxYsADJg1cuACcPi3X+fl278KdJb3PXBlp6HncHDvGJtZgUVoqZzkZjcD48Th6VPJJYiKQnq714IgCT4Q7d37//fdtbq9btw7JycnYu3cv5syZY/drZsyYgRk9Zcr777/fw2GSptSqSGYmEB9v9y7cedX71MrIobJIdGVkI6L2hDSxXn21tgOj/qlTNNOnA2FhNo8PVg6J+hpQz0hjYyMAIMnBUk9Ptbe3o6mpyeaNNNRP8yrA+XBfGD1aXli3tQHl45bIBzlVExx6Na+yckjknMdhxGQyYeXKlZg9ezYmOlnu6Yni4mIkJCSY3zIyMrz6/clN/TSvNjQAZ87IKz4neYXcFBYGFBTI9f4h18gFm1iDA5tXidzicRgpKirC4cOHsWHDBm+OBwCwevVqNDY2mt9qa2u9/jPIDf00r6qv+saMAQYN8tOYdMLcN2Lq+SvGMBL4Ll+2PCgYRohc4lbPiGrFihXYvHkzduzYgXQfdGNFR0cjOjra69+XPNRPZYRPtL5jXlFzdqRcqE2sDnp3KACUlEi3akoKkJGBs2eBujr5lJeLyEQhw63KiKIoWLFiBTZu3IitW7ciOzvbV+OiQHH2rLwZDA4P1GAY8R1zZeRIFJSMTLmhLhmlwGQ9RWMwmIskOTlyIjMR9eVWGCkqKsKrr76K9evXw2g0or6+HvX19bh8+bL5PsuWLcPq1avNtzs6OlBSUoKSkhJ0dHTg1KlTKCkpQWVlpff+K8h31Cma7Gxg8GC7d+EBeb4zYQIQESFHnNTmL5QPcqomsLFfhMhtboWRtWvXorGxEXPnzkVqaqr57fXXXzffp6amBnVqTRLA6dOnUVhYiMLCQtTV1eHxxx9HYWEhfvjDH3rvv4J8p58pmq4uS17hk633RUdbtnYpGX6dXDCMBDZuA0/kNrd6RhRF6fc+27Zts7mdlZXl0tdRgOqnebWiAmhvl6IJZ+18o7BQ/qDtRyG+AXB5byC7eNFySNP06QAYRohcwbNpyLl+KiPqFM3EibIUlbzP3DdyvmeJe0UF0LPHDwUYNShmZwPDhrFySOQi/vkgxxTFrTNpyDfMK2qORAOjRvXc2K/dgMgxtV+kZ4qmslI2rRs0SDaxIyL7GEbIsfp6OZcmLAwYP97uXRhGfE/d+OzkSeDCpJ5jFzhVE5gcNK9OmsTKIZEzfHiQY+oUzZgxQEyM3btwJY3vJSYCWVlyXZLCFTUBzcE28Hx8EDnHMEKO9TNF09gIVFfLNZ9sfUudqikJnyYXDCOBp64OOHVKSiBTpwJg5ZDIVQwj5Fg/zavqp9PTAS+flUi9qE2s+y9myQWbWAOPOkWTn2/ek4dhhMg1DCPkmItn0vCJ1vfMlZGyGEsTK3diDSy9pmhYOSRyHcMI2We9kqafM2n4ROt7amWktBRom/I1ucGpmsDSq3mVlUMi1zGMkH21tUBzs+xFPnas3buwBO0/6enA0KFAdzdwJJ1NrAFHUbgNPNEAMIyQfWpVZPx4ICqqz6cVhdM0/mQwWPWNRMo0AJf3BpCqKlkGHx1tLhUyjBC5jmGE7OunebWmRk6yj4x0uAUJeZm5b6Q5Ry4qK9nEGijUqsiUKebwzjBC5DqGEbLPxX6RvDwJJOR75soIm1gDT6/mVZOJlUMidzCMkH3cBj7gqJWRAwcA0zTpS2DfSIDo1S9y8qS0XEVFAePGaTguoiDBMEJ9mUyybAPo94A8rqTxn3HjZCPclhagMmu+fJB9I9rr6rJUqHo1r+bns3JI5AqGEeqruhpobZVmvJwcu3dhZcT/IiIs/79LYri8N2AcOQJcvgzEx5vLIHx8ELmHYYT6UptXc3PlL2AvbW3AsWNyzSdb/zL3jbT01P4rK4GLF7UaDgGWKZrp082n4bFySOQehhHqq5/m1bIy2e8iKQlITfXjuMiyoqY81nJ6HptYtaU2r/ZM0QCsjBC5i2GE+nKjedVg8NOYCIBVZWQ/gGk8NC8gqJWRnpU0ra1ydBDAMELkKoYR6qufPUb4qk87kyfLTEBDA1A//mr5IMOIdi5ftszJ9FRGSkulB3z4cCAlRcOxEQURhhGy1d0NHD0q1zwgL+AMGmRZKloyeLZccEWNdvbvl8fMiBGyZz9YOSTyBMMI2aqqAtrb5a+e2pPQCw/I05baN7L/cs/Wt1VVbGLVivX+Ij3Jg5VDIvcxjJAtdYomL8+8MsBaQ4O8GQwOZ3HIx9S+kZJjg9nEqrVem50BDCNEnmAYIVv9NK+qUzRjxgCDB/tpTGTDXBnZD1lOCrBvRCu9toFXFIYRIk8wjJCtfppXuX+C9tTKSGUl0DzxSrnBvhH/u3DBsmymJxTW1QFffSVFxfx8DcdGFGQYRsgWz6QJeMOHAyNH9rwKT/i6fJCVEf9TA+Do0cDQoQAsj4/x42XrfiJyDcMIWXR0AOXlcs1lvQHN3DfS0fN7qqqSV+rkP732FwH4+CDyFMMIWVRUyKFfRiOQkdHn011dlvPzOE2jLXPfyLHBQHa23GATq3/ZaV7lsncizzCMkIX1NvB2NkiorJRzaQYNkso0acdcGSkBd2LVSq/mVYCVESJPMYyQhYs7r06aZHfVL/mRWhk5dAjonNLzypxhxH9On5a3sDDzL6OjQ85tAlg5JHIX/6SQhYvLevlEq72sLDmxvqMDOJp8lXyQYcR/1CmaCRPMa9zLy4HOTvm9ZGZqODaiIMQwQhb9nNbLEnTgCAsDCgrken9nTzpkE6v/9DNFw23gidzDMEKirc2yZwLDSFBQp2pKKuPYxOpv3HmVyKsYRkiUl8tRo0OGAKmpfT7d1ARUV8s1p2kCg9rEyp1Y/UxRGEaIvIxhhIR186qdGrP66ZEjgaQkP46LHDJXRkoAZWrPihruxOp7lZVyMGF0tE0yZxgh8hzDCAnuvBp08vOByEj5u3gyfbZ8kJUR31OrIoWF8gsAcO6cLK4BHD6EiMgJhhESbF4NOlFRll9XCabIxfHjbGL1NTvNq+pKs9GjZc9AInKPW2GkuLgYM2bMgNFoRHJyMpYuXYpydftwJ/72t78hNzcXMTExmDRpEt59912PB0w+wgPygpK5b6QizrITHasjvsV+ESKvcyuMbN++HUVFRdi5cye2bNmCzs5OLFiwAC0tLQ6/5vPPP8ctt9yCu+66C/v378fSpUuxdOlSHFb/+JH2WlqAEyfk2k6NmceiBy7rvhHuxOoHnZ2WFUsMI0Re41YYef/997F8+XJMmDABBQUFWLduHWpqarDXyZPfU089heuvvx733Xcf8vLy8NBDD2Hq1Kl4+umnBzx48pKyMkkcw4fLWy81NbKaJjJSTiOlwGGzooZhxPeOHJFl8AkJwNix5g/zTBqigRlQz0hjYyMAIMnJ8oovvvgC8+fPt/nYwoUL8cUXXzj8mvb2djQ1Ndm8kQ+5uPNqbq70KVDgUDc+q60Fvhr7NbnBMOI76hTN9OnmMxG6uy2znAwjRJ7xOIyYTCasXLkSs2fPxkQn7eP19fVISUmx+VhKSgrq6+sdfk1xcTESEhLMbxl2TpAlL2LzatBKSLC0ipSETZWL48eB8+e1G1QoU5tXraZoqqqAy5eB2FgeIEnkKY/DSFFREQ4fPowNGzZ4czwAgNWrV6OxsdH8Vltb6/WfQVZcPCCPYSQwmftGqoyWv4bcidU31MqInW3gJ04EwsM1GBNRCPAojKxYsQKbN2/Gxx9/jPT0dKf3HTFiBBoaGmw+1tDQgBEjRjj8mujoaMTHx9u8kQ/xgLygxp1Y/aS11RLc2bxK5FVuhRFFUbBixQps3LgRW7duRbZ6HoYTV155JT766CObj23ZsgVXXnmleyMl32hqkg5VwG5lpK1NdooH+GQbqOyuqOFOrN63f780iKSmylbEPRhGiAYuwp07FxUVYf369di0aROMRqO57yMhIQGxsbEAgGXLlmHkyJEoLi4GANx77724+uqr8cQTT2Dx4sXYsGED9uzZg2effdbL/ynkkdJSeZ+WJufS9FJWJs+/SUlyFwo8amXk6FHg8sQZiAVYGfEF6/1FrI5MYBghGji3KiNr165FY2Mj5s6di9TUVPPb66+/br5PTU0N6urqzLdnzZqF9evX49lnn0VBQQH+/ve/46233nLa9Ep+1E/zqvUUDY9FD0xpabIiu7sbOBzdUxk5cYJNrN5mp3m1qcmyRQ+nMYk851ZlRFGUfu+zbdu2Ph+76aabcNNNN7nzo8hf2Lwa9AwGqY5s2QLsr4rHjJwcWeKxbx/Qa1k9DYCd5lXrAySHDtVgTEQhgmfT6B0PyAsJ7BvxsfPn5bRewNIkDD4+iLyFYUTvuMdISOBOrD6mBrucHGmg6sHHB5F3MIzo2YULlnPP8/P7fPrMGaChQaYBHGQVChBqZeTgQaC7kMt7vc7OFA3AMELkLQwjeqZWRTIzATt7uajNqzk5wODBfhwXuW3sWGDQINkKoyKhJ4ycOAF89ZW2AwsVdk7qVRSeSUPkLQwjesbm1ZARHm75PZUcj5cECXAnVm9RV9JYVUZ4gCSR9zCM6Bl3Xg0pat9ISQm4E6s3nToF1NVJ4lPnw2AJ63l5EkiIyHMMI3rG5tWQov6dtGli5YqagVOrIhMmyFxYDz4+iLyHYUTPnEzTdHdbsgqfbIOD9YoaZSpX1HgNm1eJfI5hRK/OnAHOnpWlMnl5fT5dWSnn0gwaxGPRg8WkSUBYmPxa69J6wkh1NZtYB8pO8yrAMELkTQwjeqWWPbKz7S6VsT4WPYz/SoJCbCyQmyvXJScSgDFj5AabWD1nMtkNI5cvA8eOyTXDCNHA8c+MXnHn1ZBkd/Mz9o14rrISaGwEYmJsHiulpZJThg0DRozQcHxEIYJhRK/cOCCPgofdbeHZN+I5tSpSWGizZMY6rPMASaKBYxjRK+4xEpJsKiNc3jtwdvYXAfj4IPI2hhE9UhSn0zQ8Fj14qWGkqgpoGjNVbrCJ1XNsXiXyC4YRPaqrk3NpwsLsbh2pFk3S0ngserAZNgxIT5frA9VWTaysjrivs7OnxIQ+28AzjBB5F8OIHqlVkbFjpTGvF563EdzYN+Ilhw/L+vbEREuogxweee6cZHk750sSkQcYRvSIO6+GNPaNeIk6RTN9us36dvXxMW6cLKcmooFjGNEjNq+GNLuVES7vdZ/avOqgX4T9VETewzCiR06aV62PReeTbXBSKyOHDwMdE3uaWE+eZBOru7gNPJHfMIzojfVKGjuVkdpa2eMpIsKymycFl6wsICFB+i/LTidIbxDAqRp3tLRYHidcSUPkcwwjelNbCzQ3ywZO6h8pK9bHokdF+Xls5BUGA3diHbD9++W0yNRUYORI84c7O2X3VYBhhMibGEb0Rn21N26c3bTBKZrQwBU1A+Rgiqa8XAKJ0QiMGqXBuIhCFMOI3rB5VRe4omaA+mle5TbwRN7FMKI3PCBPF6wrI8qUnhsnT8oGGdQ/Nq8S+RXDiN44qYy0t0sZGuA0TbBTe36amoAT59nE6pbz52U/fcBSVerBMELkGwwjemIyAWVlcm2nMlJWJj17Q4bY9OxREIqMtPyK2TfiJrUqMmaMPBisMIwQ+QbDiJ5UVwOtrUB0NJCT0+fTnA8PLewb8ZCDKZrz54FTp+TawSwnEXmIYURP1Cma3FwgPLzPp7mzZGjhTqwecnBSr7rSLDsbiI/385iIQhzDiJ7007zKA/JCi01lRE0mNTVsYnVGUVxaSUNE3sUwoidc1qsrBQXy/tQp4GxHguwtA3CqxplTp4D6eqkcqgGuByuHRL7DMKInTiojZ8/KczDgMKtQkDEapQcT4FSNy9SqyMSJwKBBNp9iWCfyHYYRvejqAo4elWs7aUOdosnJAeLi/Dgu8inuxOomB82r3d2WwiLDCJH3MYzoRVWVbCQyaJCcpNYLX/WFJrtn1DCMOOagefX4cVmIFhNjqTYRkfcwjOiFOkWTnw+E9f21M4yEJpvKyNSpcqOmRublyJbJ5DCMqI+PiRPtLkQjogFiGNELNYw4aAjhAXmhSa2MlJcDrRHxbGJ1pqJCtqyNje3zOGFYJ/IthhG9cLKShvPhoSs1FUhJkRf9hw6BUzXOqM2rhYWyha0VhhEi32IY0QsnK2kqK4G2NmknGT3az+Min+NOrC5yMEUDMIwQ+ZrbYWTHjh1YsmQJ0tLSYDAY8NZbb/X7Nc888wzy8vIQGxuL8ePH45VXXvFkrOSpjg7LCXh2KiPqE+2ECZwPD0XcidVFDlbSXLokDawApzGJfMXtMNLS0oKCggI888wzLt1/7dq1WL16Nf7jP/4DR44cwW9/+1sUFRXh7bffdnuw5KGKClnaazQCGRl9Ps2dV0ObWhkpKYElmdTWsonVWkdHT+kIfSoj6hRmWhowbJifx0WkExHufsGiRYuwaNEil+//l7/8BXfffTduvvlmAMDo0aOxe/durFmzBkuWLHH3x5MnrJtX7ZyAxxJ0aFPDyMGDQPfgeISPHy+Vsr17geuv13RsAePwYVn6npjYZ+0uHx9EvufznpH29nbExMTYfCw2Nha7du1CZ2enw69pamqyeaMBcHEbeJagQ9OYMcDgwcDly8CxY+BUjT3W/SK9AjvDCJHv+TyMLFy4EM8//zz27t0LRVGwZ88ePP/88+js7MQ5Bwd2FRcXIyEhwfyWYWdqgdzgpHm1uRk4cUKuGUZCU3i45Q8pNz9zwMHheADDOpE/+DyMPPjgg1i0aBG+9rWvITIyEt/85jdx++23yw+3s/kWAKxevRqNjY3mt9raWl8PM7Q5qYxwPlwfuC18Pxw0ryoKKyNE/uDzMBIbG4sXX3wRra2tqK6uRk1NDbKysmA0GjF8+HC7XxMdHY34+HibN/JQW5us3QXsVkb4qk8fbJb3FhbKVERtLXDmjJbDCgwtLZbqYa/KSG0t0NgIREQAubkajI1IJ/y2z0hkZCTS09MRHh6ODRs24MYbb3RYGSEvKi+XHa+GDAFGjOjzaa6k0Qfryohi5E6sNvbtk8dIWpq8WVHDel4eEBWlwdiIdMLtNHDp0iWUlJSgpKQEAHDixAmUlJSgpqYGgEyxLFu2zHz/Y8eO4dVXX0VFRQV27dqF733vezh8+DAeffRR7/wXkHPWUzRcSaNb6pkq584Bp06BUzXWHEzRAHx8EPmL22Fkz549KCwsRGHPS61Vq1ahsLAQv/71rwEAdXV15mACAN3d3XjiiSdQUFCA6667Dm1tbfj888+RZefkWPIBJ82rnA/Xj5gYeXUP9PSNcCdWCxeaV/n4IPItt/cZmTt3LhRFcfj5devW2dzOy8vDfnUzIfI/J82rX37J+XA9mTJF/jns3w/ceDWX95qxMkKkOTZthDonlRH1iTY3l/PhemCzokZtYv3yS303sX71lWWvd7Va1KOtrWdfFjCMEPkaw0goa2mxbCLi5EwaPtHqg82KGqORTayApSoydqzsvmqlrExOtB46VE4/JiLfYRgJZWVl0hgyfLi89cJlvfqihpETJ4CLF8G+EcDlKRo7vd9E5EUMI6HMyRQNwGW9epOUBGRmyvWBA+C28ACbV4kCBMNIKHPSvNreDhw9Ktd8stUP7sRqRVFsz6TphWGEyH8YRkKZk8qIOh+emAiMHOnfYZF27O7E+uWXQEODlsPShvrfHR5uSWlWGEaI/IdhJJSpYcROZcR6iobz4fphUxkxGoHx4+UDeqyOqFM0kyYBsbE2n2pokEVGBgOQn6/B2Ih0Rt9h5MwZ4K9/lXJtqGlqAtTN57iShnqolZEjR2SqTtdTNS40r44dCwwa5McxEemUvsPIz38O3HwzcMMNlr0GQkVpqbxPS5NzaXrhShp9ysyUfw5dXT3/RPS8oob9IkQBQ79hRFFkn4XoaOD996V68NhjQGen1iPzDifNqwBX0uiVwdCrb0SvlRGTybKKiGGESHP6DSMGA/Dgg/Ksc801st3i6tUyqf7ZZ1qPbuCcNK+ePQvU1Tn8NIU4hzux6qmJ9dgxmcqMjeU0JlEA0G8YUY0bB/zzn8ArrwDDhskf8a9/HfjXfwXOn9d6dJ5zoXl19GggLs6PY6KAYFMZiYvTZxOr2rw6daoczmSls9Myy8kwQuQfDCOAvDK87TagvBz44Q/lY889J4e2vPZacDa4Opmm4RSNvqmVkQMHZLZCl30jTvpFKiqAjg5ZbDRqlJ/HRaRTDCPWkpIkhOzYIev5zp4FfvADYMECoLJS69G57sIFyzyMnXWJLEHr2/jx0irV3NzTt63HnVhdWEkzaRIQxmdIIr/gQ82eq66SGvYjjwAxMTKNM3Ei8PDDPeshA5w6RZOZCcTH9/k0w4i+RUZaVlHpcifWjo6eOSqweZUoQDCMOBIVBTzwgEx3LFggIeTBB2XCfccOrUfnnDpFY6c7tbvb8mku69UvuzuxnjoF1NdrOSz/OHRIAsmQIUBOTp9PM4wQ+R/DSH9ycmTp7/r1QEqKHOhy9dXAnXcCX32l9ejsc9K8WlUlC4diY+0+D5NO2KyoiYuT/ihAH9UR634RO9sPM4wQ+R/DiCsMBuCWW+RAl7vvlo+99JI8gb/8cuA1uDppXlWfaCdOlCM5SJ9sKiOAvqZqnJzUe+ECUFsr11z2TuQ/DCPuGDIE+POfZR+SiROBc+eA5ctln5Lycq1HZ+FkjxHuvEqA5Uyiurqe7UX0FEacNK+qK81GjQISEvw4JiKdYxjxxKxZwL59wJo1Mt+xbZs8u//Hf8gciJbOnJFVQAYDkJfX59Nc1kuAzMyMHSvXJSXQz/LeS5csm4iweZUoYDCMeCoyEvjlL6UKsWiRNMT99rdAQQHw8cfajUutiowebfeELz7Zkkqdqikp6bmhhybWfftkc5WRI4HU1D6f5uODSBsMIwOVnQ28846c/jtihGwzfc01wO23S4XC35w0r5r3lQCnacjSxGreiVUPTaxOpmgAhhEirTCMeIPBANx0k6y0KSqS26+8Ik/uL7zQs82lnzhpXlVzSmqq7HxP+mZTGQH0MVXjpHnVZOI0JpFWGEa8KSEBePppYOdOma45f162l5871zJP7WsuNK/yiZYAS2Xk2DGgpQX62InVSWXk+HGgtVX2ORwzxs/jItI5hhFfmDlTntCfeEL6Nj75RF6G/r//B1y+7LufqyhOp2m4koaspaTIzKKi9PzbCPUVNefOASdOyLX632pFrYpMmNDn7Dwi8jGGEV+JiABWrZKKyJIlchToI49IEtiyxTc/s65ONkoIC7OcxGqFJWjqzWbzsylT5N/O6dOh2cSqVkXGjQMSE/t8mpVDIu0wjPjaqFHApk3Am29KB39VlWwvf+utPRs8eJFaFRk7VmrNVsyvfsEnW7Kw2fws1JtY2bxKFLAYRvzBYAC+9S3ZwfXee+XV5/r18sT/7LPea3B10rz65ZfAxYtSsFH/3hDZVEaA0O4bcdK8CjCMEGmJYcSfjEbgySflSXHqVEkHd98tpwSrcygD4ULzqnp8PBFgqYwcOgR0dSF0+0YUxfZMml4uXZKiJcCeKiIt6DqMVFXJbMmlS37+wdOmAf/3fxJM4uKAzz+XcHL//dLO7yknzavsFyF7cnLkn2BbW8+JBqG6vLe2VnYnjoiwJDArR45IXklNBYYP9//wiPROt2HEZAKWLpXZkhtu0CCQRETIlE1ZmUzhdHXJ9vITJgDvvef+93NxJQ3DCFkLC5NV6EBP34h1E2tdnZZD8y51imbSJDnCoReuNCPSlm7DSFgY8PzzQHy8rLzVJJAAQHq6NLdu2gRkZADV1TKYm292749Bba1ssRoZaTl0xAqfbMkRm76RwYNDs4mVzatEAU23YQQArrhCVtkmJEggWbRI/p5r4hvfkGXAq1YB4eGyvXxuLvCnPwHd3f1/vdq8Om4cEBVl86n2dsuhwnyypd5sVtQAoTlVw+ZVooCm6zACyAslNZB8+qnGgSQuTjZK27NHBtbUJNvLz5pltdzBASfNq0ePyixQYqIUYoisWVdGFAWhtaLm4kU5uFINVnbCCJe9E2lP92EEkOcnNZB89pnGgQSQl6qffy5byxuN8qpu+nTgF79wPJfk4s6rBoNvhkzBS91x9Px5me0L2hU1Z84A778PPPqonBWVkwMMGSIHVzY3S9jPz+/zZVz2TqQ9hpEeM2YA//ynVA8++wy4/nopTGgmPFyqIkePyhNrd7dUTSZMAN5+u+/9newxwpU05Ex0tOVvtM1OrHV1gdnEqiiSmjZtAn7zG9nhOD1d9rdftAj41a+Av//dckR1Vhbw7W8Dr71md593Nazn5nLZO5FW3A4jO3bswJIlS5CWlgaDwYC33nqr36957bXXUFBQgEGDBiE1NRV33nknvvrqK0/G61PTp1sCyeefB0AgAYC0NOkfeecd2c21pkb6S77zHXlJB8jSIPUgPh6QRx6w6RsZPBjIy5MPaF0dMZmAigp5DNx/v+xePHw4kJkpy+H+8z+BzZuBU6ek7Dd+PHDLLcB//Rfw0UfAV1/JeTRvvCGPGzsY1om053YYaWlpQUFBAZ555hmX7v/ZZ59h2bJluOuuu3DkyBH87W9/w65du/CjH/3I7cH6w7RpEkiGDAG++CJAAgkgK2yOHAF++Uupmrz5pvzB+O//Bior5QC+6GgpTffClTTUn4DYibWrSyp8r7wC/OxnwNVXyyuDceNkddmaNTKf+tVXUuGYPBlYvlweA59+Kg/Uo0dlvf4vfiHTM0lJ/f5YhnUi7bl9NuWiRYuwaNEil+//xRdfICsrCz/96U8BANnZ2bj77ruxZs0ad3+036iBZP58CSQLF8pUdEKCxgMbPFiekG+9VXZu3blT9ioZMUI+n5cnQcXKuXOWSrudogkRADsraqZNk1Dgq8pIe7sEj3375Ifu2wccOCC7r/UWHS2boRQWyuaAU6fKP+Ze5y95imGESHs+Pyj7yiuvxAMPPIB3330XixYtwpkzZ/D3v/8dN9xwg8OvaW9vR3t7u/l2kwalialTLYFk504JJB98EACBBJBnzc8+k3Nt7r/fcsKqk36R0aOlF5bIHjWMnDwpBz8P8eby3pYWCRr79lnCx+HDPfvP9xIXZwkd6vvcXNk/xwfa26WYAjCMEGnJ52Fk9uzZeO2113DzzTejra0NXV1dWLJkidNpnuLiYvz2t7/19dD6NXWqTDvPny+7twdUIAkLA378Y5k3/9nPpGFvyZI+d+MUDbkiMVH6PKurZapm3hVTLE2sp09L75IrLlyQb6AGj337ZJMbRel736QkS6VDDR9jxsjP9ZOyMukNT0py/T+RiLzP52GktLQU9957L379619j4cKFqKurw3333Ycf//jHeOGFF+x+zerVq7Fq1Srz7aamJmRkZPh6qHYVFkogufZaCSQLFkggSUzUZDh9jRgB/O//Ai+/3GezM4AlaHJdYaFVGJk3SKb9jhyR6oi9v9QNDZYpFvXtxAn73zw1tW/wyMzUfK259eODy96JtOPzMFJcXIzZs2fjvvvuAwBMnjwZgwcPxlVXXYWHH34Yqampfb4mOjoa0QG0xm7KFEsg2bVLAsmHHwZQIAHsBhGAKwXIdVOmABs39tqJVQ0jBQW2/R379knFxJ7sbNv+jsJCS19TgGHlkCgw+DyMtLa2IqLX2v7wniZLxV7pNkBNmQJs3SqBZPfuAA0kvXR3W7YfYRih/thdUfPyy7J81t60qbqU1rq/Y8oUl1awBApWDokCg9th5NKlS6isrDTfPnHiBEpKSpCUlITMzEysXr0ap06dwiuvvAIAWLJkCX70ox9h7dq15mmalStXYubMmUgLsknaggJLhWT3buC66ySQDBmi9cjsq6qSFb+xsXZX/BLZUJtYS0tlUUvMvHkSOBRFltJOmGBb7SgokIbTIMYwQhQY3A4je/bswbx588y31d6O22+/HevWrUNdXR1qamrMn1++fDmam5vx9NNP4+c//zkSExNxzTXXBPTSXmcKCiwVkj17JJBs2RKYgUSdopkwoc+KX6I+0tOlqHH+vMzOTJs2UaZlOju9upQ2UDQ0yJvBYHchGhH5kdthZO7cuU6nV9atW9fnY/fccw/uueced39UwJo8WQLJNdfIdHqgBhK+6iN3GAyWhu39+3v2PSso0HpYPqOG9TFjZAsfItIOz6bx0KRJEkiGDZNAMn++vKIMJGzOI3epUzX9HRIdCtjcTRQ4GEYGYNIkOZ18+HBZXHDddYEVSPhkS+5Sm1jNK2pCGCuHRIGDYWSAJk6UCokaSAKlQnLpkjSwAqyMkOvUysiBA3JGXShjGCEKHAwjXjBxolRIkpPlFWUgBBJ1Se+IERKUiFwxfrz0qba0yPmLoaqrS5p0AYYRokDAMOIlEybYBpJrr5XDRbXCKRryRESEpZIWyn0jFRVyLk1cnGyDT0TaYhjxovx8CSQpKfJEPn++doGEJWjylB76Rqybu/14FA4ROcCHoZf1DiTXXgucO+f/cXAlDXlKDytqGNaJAgvDiA/k5VkCyYED/g8kisInW/Kc3iojRKQ9hhEfycsDtm2TBtKDB/0bSE6dAi5elF1X8/L88zMpdEyaJBugNTQA9fVaj8Y3GNaJAgvDiA/l5kqFRA0k11wDnD3r+5+rPtGOHw8E0OHHFCQGD5Z/O0BoTtVcvAioJ1awMkIUGBhGfCw3VyokqamywuXaa30fSPiqjwZK7RsJxakadaVZZmZgn7pNpCcMI34wfrxUSNRAcs01wJkzvvt5XNZLA6X2jYRiZYRhnSjwMIz4yfjxUiFJS5MNyXwZSPhkSwOlh8oIHx9EgYNhxI/GjbMEkiNHfBNIOjqAo0flmvPh5Ck1jFRWAs3Nmg7F6xjWiQIPw4ifjR0rgWTkSAkk8+bJqgVvOXpUtrpOSAAyMrz3fUlfkpMlNFsvEw8FJhMrI0SBiGFEA9aBpLRUKiTeCiTWr/oMBu98T9KnUOwbqa6WQySjo+VxSESBgWFEI2PGSCBJT5dAMm+ed/Z04GZO5C2h2DeiPj4mTJBzeIgoMDCMaGjMGFllk54OlJV5J5CwBE3eolZGXnwRuPJK4KGHgH37ZKojWLFfhCgwMYxozLpCcvSoBJK6Os+/H59syVuuu05CiKIAO3cCv/41MG2aTC/eeSfwxhtAU5PWo3QPHx9EgYlhJADk5EggycgYWCA5dw44fVquJ0706hBJh+Ljgc8/B2prgWefBZYuld1Z6+uBl14CvvtdYOhQ6Xl6/HGp7imK1qN2jtOYRIHJoCiB/vQBNDU1ISEhAY2NjYiPj9d6OD5z/Dgwd648+VtvlOaqjz+WPwzZ2fK9iLytvR345BPgnXeAd98Fjh2z/XxWFnDDDcDixRKqY2M1GaZdLS2A0SiBqaFBVgwRkW+5+veblZEAMnq0VEgyM4HycgkmaqXDFewXIV+Ljgbmzwf+8Af5N1pRATz1FLBgARAVJatV/vQnCSNJSfL+mWfk41o7ckSCSEoKgwhRoGEYCTDWgeTYMXl16WogYQma/G3MGOCnPwU++AA4fx7YtAm4+27pgWprk+rJihVSrcvPB+67Typ4HR3+Hyv7RYgCF8NIAMrOlkAyapQEElcrJHyyJS0NHgx84xvAn/8sp+IePAg89hhw1VVAeLj0lDz+uEwlDhsmPScvvjiwhm13sHJIFLgYRgKUdSCpqJBAcuqU4/t3d0sZGuCTLWnPYJAK3b//O7Bjh5xUvWEDsGwZMHy4bDH/xhvAXXfJTq/TpslqnZ075d+yLzCsEwUuNrAGuOpqmaqprpYdIz/+WJZW9lZRIWffxMTIDpPh4f4eKZFrTCZgzx6ZwnnnHbm2NmwYcP310gi7cKH0ngyUosj3PX9eNnFTN3QjIt9y9e83w0gQOHlSKiPV1bYbpVl74w0pe0+b1vfJnSiQNTQA770n4eSDD2z3LgkLk71OFi+WcOLpMQenTsljJjxcVtVER3tv/ETkGFfThJBRo2TKJjtbTlGdOxf48kvb+3A+nIJVSgqwfDnw17/KXjnbtgG//KVs2W4yAZ99BjzwgFQzMjKAf/1XaZS9dMn1n6FO0eTmMogQBSKGkSBhHUiqqiz7kag4H06hIDISuPpqYM0a4PBhy1LhG2+UPUtOnQKee042YBs6VHaJffLJvvud9MbHB1FgYxgJIpmZEkhGj+4bSLisl0LRqFHAv/0b8Pbb0u/x3nvAPffIY6CjA/jnP4Gf/Uw2CRw7Frj3XuDDD2VZsTWGEaLAxp6RIFRbK0Hk+HF5Ut68WUraigKcOSOrFYhCmaJINUTdCXbHDqCz0/L5QYOAa6+19JrccINUWt55R66JyD/YwBriamtllU1VFZCYCFy8CIwY4b89G4gCSXOzVEnefVfeHO3LU1MjfSdE5B9sYA1xGRkyZZOTI0EE4BQN6ZfRCHzrW9JP8uWXsnz34YeBWbNkRQ4gq2l6r0IjosDAMBLE0tMlkIwZI7enTdN0OEQBwWCQlTe/+pWsxDlzRpa+b9ni2bJgIvK9CK0HQAOTng58+qksi/z+97UeDVHgGToU+Pa3tR4FETnDMBICUlJkhQEREVEwcnuaZseOHViyZAnS0tJgMBjw1ltvOb3/8uXLYTAY+rxNmDDB0zETERFRCHE7jLS0tKCgoADPPPOMS/d/6qmnUFdXZ36rra1FUlISbrrpJrcHS0RERKHH7WmaRYsWYdGiRS7fPyEhAQkJCebbb731Fi5cuIA77rjD3R9NREREIcjvq2leeOEFzJ8/H6NGjfL3jyYiIqIA5NcG1tOnT+O9997D+vXrnd6vvb0d7e3t5ttN1sd4EhERUUjxa2Xk5ZdfRmJiIpYuXer0fsXFxebpnYSEBGRwy0QiIqKQ5bcwoigKXnzxRdx2222Iiopyet/Vq1ejsbHR/FZrfTwtERERhRS/TdNs374dlZWVuOuuu/q9b3R0NKKjo/0wKiIiItKa22Hk0qVLqKysNN8+ceIESkpKkJSUhMzMTKxevRqnTp3CK6+8YvN1L7zwAq644gpMnDhx4KMmIiKikOF2GNmzZw/mzZtnvr1q1SoAwO23345169ahrq4ONTU1Nl/T2NiIN954A0899dQAh0tEREShxqAoiqL1IPrj6hHEREREFDhc/fvNU3uJiIhIUwwjREREpKmgOLVXnUni5mdERETBQ/273V9HSFCEkebmZgDg5mdERERBqLm52eacut6CooHVZDLh9OnTMBqNMBgMXvu+TU1NyMjIQG1tLRtjAwR/J4GFv4/Awt9HYOHvo3+KoqC5uRlpaWkIC3PcGRIUlZGwsDCkp6f77PvHx8fzH1KA4e8ksPD3EVj4+wgs/H0456wiomIDKxEREWmKYYSIiIg0peswEh0djd/85jc8ByeA8HcSWPj7CCz8fQQW/j68JygaWImIiCh06boyQkRERNpjGCEiIiJNMYwQERGRphhGiIiISFO6DiPPPPMMsrKyEBMTgyuuuAK7du3Seki6VFxcjBkzZsBoNCI5ORlLly5FeXm51sOiHo899hgMBgNWrlyp9VB07dSpU/jBD36AoUOHIjY2FpMmTcKePXu0HpYudXd348EHH0R2djZiY2ORk5ODhx56qN/zV8gx3YaR119/HatWrcJvfvMb7Nu3DwUFBVi4cCHOnDmj9dB0Z/v27SgqKsLOnTuxZcsWdHZ2YsGCBWhpadF6aLq3e/du/M///A8mT56s9VB07cKFC5g9ezYiIyPx3nvvobS0FE888QSGDBmi9dB0ac2aNVi7di2efvpplJWVYc2aNfjd736HP/7xj1oPLWjpdmnvFVdcgRkzZuDpp58GIOffZGRk4J577sH999+v8ej07ezZs0hOTsb27dsxZ84crYejW5cuXcLUqVPxpz/9CQ8//DCmTJmCJ598Uuth6dL999+Pzz77DJ988onWQyEAN954I1JSUvDCCy+YP/ad73wHsbGxePXVVzUcWfDSZWWko6MDe/fuxfz5880fCwsLw/z58/HFF19oODICgMbGRgBAUlKSxiPRt6KiIixevNjmcULa+Mc//oHp06fjpptuQnJyMgoLC/Hcc89pPSzdmjVrFj766CMcO3YMAHDgwAF8+umnWLRokcYjC15BcVCet507dw7d3d1ISUmx+XhKSgqOHj2q0agIkArVypUrMXv2bEycOFHr4ejWhg0bsG/fPuzevVvroRCA48ePY+3atVi1ahUeeOAB7N69Gz/96U8RFRWF22+/Xevh6c7999+PpqYm5ObmIjw8HN3d3XjkkUdw6623aj20oKXLMEKBq6ioCIcPH8ann36q9VB0q7a2Fvfeey+2bNmCmJgYrYdDkJA+ffp0PProowCAwsJCHD58GH/+858ZRjTw17/+Fa+99hrWr1+PCRMmoKSkBCtXrkRaWhp/Hx7SZRgZNmwYwsPD0dDQYPPxhoYGjBgxQqNR0YoVK7B582bs2LED6enpWg9Ht/bu3YszZ85g6tSp5o91d3djx44dePrpp9He3o7w8HANR6g/qampyM/Pt/lYXl4e3njjDY1GpG/33Xcf7r//fnzve98DAEyaNAknT55EcXExw4iHdNkzEhUVhWnTpuGjjz4yf8xkMuGjjz7ClVdeqeHI9ElRFKxYsQIbN27E1q1bkZ2drfWQdO3aa6/FoUOHUFJSYn6bPn06br31VpSUlDCIaGD27Nl9lrsfO3YMo0aN0mhE+tba2oqwMNs/n+Hh4TCZTBqNKPjpsjICAKtWrcLtt9+O6dOnY+bMmXjyySfR0tKCO+64Q+uh6U5RURHWr1+PTZs2wWg0or6+HgCQkJCA2NhYjUenP0ajsU+/zuDBgzF06FD28WjkZz/7GWbNmoVHH30U//Iv/4Jdu3bh2WefxbPPPqv10HRpyZIleOSRR5CZmYkJEyZg//79+P3vf48777xT66EFL0XH/vjHPyqZmZlKVFSUMnPmTGXnzp1aD0mXANh9e+mll7QeGvW4+uqrlXvvvVfrYeja22+/rUycOFGJjo5WcnNzlWeffVbrIelWU1OTcu+99yqZmZlKTEyMMnr0aOVXv/qV0t7ervXQgpZu9xkhIiKiwKDLnhEiIiIKHAwjREREpCmGESIiItIUwwgRERFpimGEiIiINMUwQkRERJpiGCEiIiJNMYwQERGRphhGiIiISFMMI0RERKQphhEiIiLSFMMIERERaer/A+YuK8pYrP9bAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "Training for 10 epochs with learning rate: 0.1\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.314358  [    0/60000]\n",
      "loss: 0.905528  [ 6400/60000]\n",
      "loss: 0.577877  [12800/60000]\n",
      "loss: 0.697705  [19200/60000]\n",
      "loss: 0.594135  [25600/60000]\n",
      "loss: 0.509790  [32000/60000]\n",
      "loss: 0.535337  [38400/60000]\n",
      "loss: 0.602574  [44800/60000]\n",
      "loss: 0.604390  [51200/60000]\n",
      "loss: 0.466300  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.546210 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.417352  [    0/60000]\n",
      "loss: 0.450595  [ 6400/60000]\n",
      "loss: 0.370296  [12800/60000]\n",
      "loss: 0.421128  [19200/60000]\n",
      "loss: 0.398313  [25600/60000]\n",
      "loss: 0.459016  [32000/60000]\n",
      "loss: 0.407032  [38400/60000]\n",
      "loss: 0.523459  [44800/60000]\n",
      "loss: 0.507857  [51200/60000]\n",
      "loss: 0.429652  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.467544 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.320501  [    0/60000]\n",
      "loss: 0.367953  [ 6400/60000]\n",
      "loss: 0.307655  [12800/60000]\n",
      "loss: 0.356593  [19200/60000]\n",
      "loss: 0.339288  [25600/60000]\n",
      "loss: 0.418567  [32000/60000]\n",
      "loss: 0.350293  [38400/60000]\n",
      "loss: 0.467469  [44800/60000]\n",
      "loss: 0.446449  [51200/60000]\n",
      "loss: 0.407180  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.422361 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.257858  [    0/60000]\n",
      "loss: 0.341316  [ 6400/60000]\n",
      "loss: 0.260671  [12800/60000]\n",
      "loss: 0.316100  [19200/60000]\n",
      "loss: 0.321868  [25600/60000]\n",
      "loss: 0.398264  [32000/60000]\n",
      "loss: 0.328201  [38400/60000]\n",
      "loss: 0.440439  [44800/60000]\n",
      "loss: 0.406796  [51200/60000]\n",
      "loss: 0.382060  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.403264 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.239320  [    0/60000]\n",
      "loss: 0.318865  [ 6400/60000]\n",
      "loss: 0.235119  [12800/60000]\n",
      "loss: 0.293307  [19200/60000]\n",
      "loss: 0.315777  [25600/60000]\n",
      "loss: 0.380655  [32000/60000]\n",
      "loss: 0.303856  [38400/60000]\n",
      "loss: 0.403000  [44800/60000]\n",
      "loss: 0.373489  [51200/60000]\n",
      "loss: 0.367749  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.385587 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.222655  [    0/60000]\n",
      "loss: 0.303184  [ 6400/60000]\n",
      "loss: 0.209105  [12800/60000]\n",
      "loss: 0.273082  [19200/60000]\n",
      "loss: 0.312086  [25600/60000]\n",
      "loss: 0.363625  [32000/60000]\n",
      "loss: 0.290599  [38400/60000]\n",
      "loss: 0.387051  [44800/60000]\n",
      "loss: 0.342360  [51200/60000]\n",
      "loss: 0.358787  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.378884 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.215302  [    0/60000]\n",
      "loss: 0.294445  [ 6400/60000]\n",
      "loss: 0.191619  [12800/60000]\n",
      "loss: 0.252190  [19200/60000]\n",
      "loss: 0.303888  [25600/60000]\n",
      "loss: 0.359901  [32000/60000]\n",
      "loss: 0.281138  [38400/60000]\n",
      "loss: 0.340635  [44800/60000]\n",
      "loss: 0.336917  [51200/60000]\n",
      "loss: 0.343379  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.372655 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.200574  [    0/60000]\n",
      "loss: 0.278707  [ 6400/60000]\n",
      "loss: 0.184895  [12800/60000]\n",
      "loss: 0.239064  [19200/60000]\n",
      "loss: 0.303513  [25600/60000]\n",
      "loss: 0.337800  [32000/60000]\n",
      "loss: 0.266641  [38400/60000]\n",
      "loss: 0.330100  [44800/60000]\n",
      "loss: 0.323491  [51200/60000]\n",
      "loss: 0.334703  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.367703 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.192590  [    0/60000]\n",
      "loss: 0.265037  [ 6400/60000]\n",
      "loss: 0.174457  [12800/60000]\n",
      "loss: 0.228721  [19200/60000]\n",
      "loss: 0.302266  [25600/60000]\n",
      "loss: 0.324230  [32000/60000]\n",
      "loss: 0.249188  [38400/60000]\n",
      "loss: 0.316632  [44800/60000]\n",
      "loss: 0.292780  [51200/60000]\n",
      "loss: 0.321027  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.360331 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.185383  [    0/60000]\n",
      "loss: 0.257161  [ 6400/60000]\n",
      "loss: 0.169584  [12800/60000]\n",
      "loss: 0.218710  [19200/60000]\n",
      "loss: 0.297620  [25600/60000]\n",
      "loss: 0.319424  [32000/60000]\n",
      "loss: 0.238993  [38400/60000]\n",
      "loss: 0.295986  [44800/60000]\n",
      "loss: 0.282355  [51200/60000]\n",
      "loss: 0.311846  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.365612 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "Training for 10 epochs with learning rate: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305028  [    0/60000]\n",
      "loss: 2.174147  [ 6400/60000]\n",
      "loss: 1.807640  [12800/60000]\n",
      "loss: 1.532810  [19200/60000]\n",
      "loss: 1.165420  [25600/60000]\n",
      "loss: 1.039437  [32000/60000]\n",
      "loss: 1.018623  [38400/60000]\n",
      "loss: 0.875294  [44800/60000]\n",
      "loss: 0.879659  [51200/60000]\n",
      "loss: 0.808442  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.793218 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.795030  [    0/60000]\n",
      "loss: 0.846376  [ 6400/60000]\n",
      "loss: 0.576975  [12800/60000]\n",
      "loss: 0.785442  [19200/60000]\n",
      "loss: 0.674387  [25600/60000]\n",
      "loss: 0.637084  [32000/60000]\n",
      "loss: 0.712442  [38400/60000]\n",
      "loss: 0.685313  [44800/60000]\n",
      "loss: 0.706451  [51200/60000]\n",
      "loss: 0.638782  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.632514 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.564046  [    0/60000]\n",
      "loss: 0.651614  [ 6400/60000]\n",
      "loss: 0.432722  [12800/60000]\n",
      "loss: 0.669484  [19200/60000]\n",
      "loss: 0.591178  [25600/60000]\n",
      "loss: 0.560467  [32000/60000]\n",
      "loss: 0.592433  [38400/60000]\n",
      "loss: 0.641004  [44800/60000]\n",
      "loss: 0.670292  [51200/60000]\n",
      "loss: 0.550344  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.569953 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.472737  [    0/60000]\n",
      "loss: 0.561944  [ 6400/60000]\n",
      "loss: 0.374135  [12800/60000]\n",
      "loss: 0.605929  [19200/60000]\n",
      "loss: 0.535129  [25600/60000]\n",
      "loss: 0.519404  [32000/60000]\n",
      "loss: 0.537393  [38400/60000]\n",
      "loss: 0.639971  [44800/60000]\n",
      "loss: 0.650100  [51200/60000]\n",
      "loss: 0.487333  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.539823 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.419037  [    0/60000]\n",
      "loss: 0.517146  [ 6400/60000]\n",
      "loss: 0.341391  [12800/60000]\n",
      "loss: 0.562285  [19200/60000]\n",
      "loss: 0.490656  [25600/60000]\n",
      "loss: 0.491527  [32000/60000]\n",
      "loss: 0.507178  [38400/60000]\n",
      "loss: 0.638014  [44800/60000]\n",
      "loss: 0.626238  [51200/60000]\n",
      "loss: 0.448713  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.519722 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.378025  [    0/60000]\n",
      "loss: 0.490616  [ 6400/60000]\n",
      "loss: 0.319133  [12800/60000]\n",
      "loss: 0.532634  [19200/60000]\n",
      "loss: 0.458098  [25600/60000]\n",
      "loss: 0.472725  [32000/60000]\n",
      "loss: 0.486979  [38400/60000]\n",
      "loss: 0.627667  [44800/60000]\n",
      "loss: 0.603441  [51200/60000]\n",
      "loss: 0.427098  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.504508 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.345594  [    0/60000]\n",
      "loss: 0.472754  [ 6400/60000]\n",
      "loss: 0.301761  [12800/60000]\n",
      "loss: 0.513021  [19200/60000]\n",
      "loss: 0.433292  [25600/60000]\n",
      "loss: 0.459919  [32000/60000]\n",
      "loss: 0.471630  [38400/60000]\n",
      "loss: 0.615112  [44800/60000]\n",
      "loss: 0.585334  [51200/60000]\n",
      "loss: 0.415131  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.493069 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.321781  [    0/60000]\n",
      "loss: 0.458099  [ 6400/60000]\n",
      "loss: 0.288420  [12800/60000]\n",
      "loss: 0.497573  [19200/60000]\n",
      "loss: 0.411913  [25600/60000]\n",
      "loss: 0.448977  [32000/60000]\n",
      "loss: 0.457223  [38400/60000]\n",
      "loss: 0.601620  [44800/60000]\n",
      "loss: 0.568823  [51200/60000]\n",
      "loss: 0.406456  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.482166 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.303418  [    0/60000]\n",
      "loss: 0.445185  [ 6400/60000]\n",
      "loss: 0.277926  [12800/60000]\n",
      "loss: 0.484718  [19200/60000]\n",
      "loss: 0.393063  [25600/60000]\n",
      "loss: 0.438768  [32000/60000]\n",
      "loss: 0.444868  [38400/60000]\n",
      "loss: 0.588437  [44800/60000]\n",
      "loss: 0.553582  [51200/60000]\n",
      "loss: 0.399490  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.472239 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.289786  [    0/60000]\n",
      "loss: 0.432574  [ 6400/60000]\n",
      "loss: 0.269285  [12800/60000]\n",
      "loss: 0.472983  [19200/60000]\n",
      "loss: 0.377496  [25600/60000]\n",
      "loss: 0.429938  [32000/60000]\n",
      "loss: 0.432891  [38400/60000]\n",
      "loss: 0.575851  [44800/60000]\n",
      "loss: 0.540443  [51200/60000]\n",
      "loss: 0.393845  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.462836 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "Training for 10 epochs with learning rate: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.304691  [    0/60000]\n",
      "loss: 2.291551  [ 6400/60000]\n",
      "loss: 2.272370  [12800/60000]\n",
      "loss: 2.263115  [19200/60000]\n",
      "loss: 2.261454  [25600/60000]\n",
      "loss: 2.226220  [32000/60000]\n",
      "loss: 2.231131  [38400/60000]\n",
      "loss: 2.194508  [44800/60000]\n",
      "loss: 2.194481  [51200/60000]\n",
      "loss: 2.164686  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 2.153214 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.166766  [    0/60000]\n",
      "loss: 2.153075  [ 6400/60000]\n",
      "loss: 2.093805  [12800/60000]\n",
      "loss: 2.102123  [19200/60000]\n",
      "loss: 2.072922  [25600/60000]\n",
      "loss: 2.012287  [32000/60000]\n",
      "loss: 2.032425  [38400/60000]\n",
      "loss: 1.951991  [44800/60000]\n",
      "loss: 1.958705  [51200/60000]\n",
      "loss: 1.892366  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 1.880416 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.920475  [    0/60000]\n",
      "loss: 1.884442  [ 6400/60000]\n",
      "loss: 1.765658  [12800/60000]\n",
      "loss: 1.797194  [19200/60000]\n",
      "loss: 1.721726  [25600/60000]\n",
      "loss: 1.668545  [32000/60000]\n",
      "loss: 1.681053  [38400/60000]\n",
      "loss: 1.580691  [44800/60000]\n",
      "loss: 1.608575  [51200/60000]\n",
      "loss: 1.509169  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 1.518187 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.585440  [    0/60000]\n",
      "loss: 1.548900  [ 6400/60000]\n",
      "loss: 1.398199  [12800/60000]\n",
      "loss: 1.469139  [19200/60000]\n",
      "loss: 1.374607  [25600/60000]\n",
      "loss: 1.358583  [32000/60000]\n",
      "loss: 1.372190  [38400/60000]\n",
      "loss: 1.291795  [44800/60000]\n",
      "loss: 1.325423  [51200/60000]\n",
      "loss: 1.234853  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.252655 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.320980  [    0/60000]\n",
      "loss: 1.306749  [ 6400/60000]\n",
      "loss: 1.141178  [12800/60000]\n",
      "loss: 1.249636  [19200/60000]\n",
      "loss: 1.136433  [25600/60000]\n",
      "loss: 1.154163  [32000/60000]\n",
      "loss: 1.176482  [38400/60000]\n",
      "loss: 1.110908  [44800/60000]\n",
      "loss: 1.143305  [51200/60000]\n",
      "loss: 1.069558  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.083862 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.141801  [    0/60000]\n",
      "loss: 1.150957  [ 6400/60000]\n",
      "loss: 0.969823  [12800/60000]\n",
      "loss: 1.109222  [19200/60000]\n",
      "loss: 0.986365  [25600/60000]\n",
      "loss: 1.016321  [32000/60000]\n",
      "loss: 1.053006  [38400/60000]\n",
      "loss: 0.996504  [44800/60000]\n",
      "loss: 1.025172  [51200/60000]\n",
      "loss: 0.964110  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.974538 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.017714  [    0/60000]\n",
      "loss: 1.049808  [ 6400/60000]\n",
      "loss: 0.853058  [12800/60000]\n",
      "loss: 1.015719  [19200/60000]\n",
      "loss: 0.891635  [25600/60000]\n",
      "loss: 0.920068  [32000/60000]\n",
      "loss: 0.972079  [38400/60000]\n",
      "loss: 0.923414  [44800/60000]\n",
      "loss: 0.944643  [51200/60000]\n",
      "loss: 0.893897  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.900934 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.927694  [    0/60000]\n",
      "loss: 0.980382  [ 6400/60000]\n",
      "loss: 0.771020  [12800/60000]\n",
      "loss: 0.950989  [19200/60000]\n",
      "loss: 0.828941  [25600/60000]\n",
      "loss: 0.851254  [32000/60000]\n",
      "loss: 0.915858  [38400/60000]\n",
      "loss: 0.875387  [44800/60000]\n",
      "loss: 0.887922  [51200/60000]\n",
      "loss: 0.844168  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.848927 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.859631  [    0/60000]\n",
      "loss: 0.929398  [ 6400/60000]\n",
      "loss: 0.710779  [12800/60000]\n",
      "loss: 0.903946  [19200/60000]\n",
      "loss: 0.784938  [25600/60000]\n",
      "loss: 0.800891  [32000/60000]\n",
      "loss: 0.874261  [38400/60000]\n",
      "loss: 0.842759  [44800/60000]\n",
      "loss: 0.846139  [51200/60000]\n",
      "loss: 0.806789  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.810085 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.805865  [    0/60000]\n",
      "loss: 0.888950  [ 6400/60000]\n",
      "loss: 0.664449  [12800/60000]\n",
      "loss: 0.868240  [19200/60000]\n",
      "loss: 0.751959  [25600/60000]\n",
      "loss: 0.762796  [32000/60000]\n",
      "loss: 0.841272  [38400/60000]\n",
      "loss: 0.819107  [44800/60000]\n",
      "loss: 0.813848  [51200/60000]\n",
      "loss: 0.777193  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.779407 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train and test the model\n",
    "epochs = 10\n",
    "\n",
    "learning_rates = [1, 1e-1, 1e-2, 1e-3]\n",
    "\n",
    "for rate in learning_rates:\n",
    "    print(f\"Training for {epochs} epochs with learning rate: {rate}\")\n",
    "    model = NeuralNetwork().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loss, _ = test(test_dataloader, model, loss_fn)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    plt.plot(np.array(train_losses), 'r')\n",
    "    plt.plot(np.array(test_losses), 'b')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Lr|Accuracy|\n",
    "|---|---|\n",
    "|1   |    10%  |\n",
    "|0.1|     87.5%   |\n",
    "|0.01|     83.3%    |\n",
    "|0.001  |    70.3%  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate: 0.01 until reaching 85% accuracy\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.310285  [    0/60000]\n",
      "loss: 2.175589  [ 6400/60000]\n",
      "loss: 1.858122  [12800/60000]\n",
      "loss: 1.549233  [19200/60000]\n",
      "loss: 1.163300  [25600/60000]\n",
      "loss: 1.056977  [32000/60000]\n",
      "loss: 1.012100  [38400/60000]\n",
      "loss: 0.869220  [44800/60000]\n",
      "loss: 0.870842  [51200/60000]\n",
      "loss: 0.804926  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.789787 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.785738  [    0/60000]\n",
      "loss: 0.840904  [ 6400/60000]\n",
      "loss: 0.589798  [12800/60000]\n",
      "loss: 0.779425  [19200/60000]\n",
      "loss: 0.664690  [25600/60000]\n",
      "loss: 0.638726  [32000/60000]\n",
      "loss: 0.711833  [38400/60000]\n",
      "loss: 0.682911  [44800/60000]\n",
      "loss: 0.703423  [51200/60000]\n",
      "loss: 0.630932  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.629330 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.551252  [    0/60000]\n",
      "loss: 0.648583  [ 6400/60000]\n",
      "loss: 0.440248  [12800/60000]\n",
      "loss: 0.659268  [19200/60000]\n",
      "loss: 0.578733  [25600/60000]\n",
      "loss: 0.560430  [32000/60000]\n",
      "loss: 0.593029  [38400/60000]\n",
      "loss: 0.643230  [44800/60000]\n",
      "loss: 0.668083  [51200/60000]\n",
      "loss: 0.543996  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.568810 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.459835  [    0/60000]\n",
      "loss: 0.562420  [ 6400/60000]\n",
      "loss: 0.380073  [12800/60000]\n",
      "loss: 0.593042  [19200/60000]\n",
      "loss: 0.524479  [25600/60000]\n",
      "loss: 0.518507  [32000/60000]\n",
      "loss: 0.538834  [38400/60000]\n",
      "loss: 0.646616  [44800/60000]\n",
      "loss: 0.648718  [51200/60000]\n",
      "loss: 0.485852  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.538848 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.406362  [    0/60000]\n",
      "loss: 0.520155  [ 6400/60000]\n",
      "loss: 0.347171  [12800/60000]\n",
      "loss: 0.549125  [19200/60000]\n",
      "loss: 0.486714  [25600/60000]\n",
      "loss: 0.488913  [32000/60000]\n",
      "loss: 0.506950  [38400/60000]\n",
      "loss: 0.642489  [44800/60000]\n",
      "loss: 0.625657  [51200/60000]\n",
      "loss: 0.449940  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.518750 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.367907  [    0/60000]\n",
      "loss: 0.495670  [ 6400/60000]\n",
      "loss: 0.324492  [12800/60000]\n",
      "loss: 0.518325  [19200/60000]\n",
      "loss: 0.462034  [25600/60000]\n",
      "loss: 0.469616  [32000/60000]\n",
      "loss: 0.482760  [38400/60000]\n",
      "loss: 0.631472  [44800/60000]\n",
      "loss: 0.604438  [51200/60000]\n",
      "loss: 0.430061  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.504005 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.338054  [    0/60000]\n",
      "loss: 0.477317  [ 6400/60000]\n",
      "loss: 0.307068  [12800/60000]\n",
      "loss: 0.497181  [19200/60000]\n",
      "loss: 0.442682  [25600/60000]\n",
      "loss: 0.457584  [32000/60000]\n",
      "loss: 0.463669  [38400/60000]\n",
      "loss: 0.618422  [44800/60000]\n",
      "loss: 0.586069  [51200/60000]\n",
      "loss: 0.418451  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.491490 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.316890  [    0/60000]\n",
      "loss: 0.461678  [ 6400/60000]\n",
      "loss: 0.293075  [12800/60000]\n",
      "loss: 0.482405  [19200/60000]\n",
      "loss: 0.425365  [25600/60000]\n",
      "loss: 0.447462  [32000/60000]\n",
      "loss: 0.448161  [38400/60000]\n",
      "loss: 0.606273  [44800/60000]\n",
      "loss: 0.568769  [51200/60000]\n",
      "loss: 0.410590  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.480953 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.301262  [    0/60000]\n",
      "loss: 0.448209  [ 6400/60000]\n",
      "loss: 0.281974  [12800/60000]\n",
      "loss: 0.470162  [19200/60000]\n",
      "loss: 0.409775  [25600/60000]\n",
      "loss: 0.438331  [32000/60000]\n",
      "loss: 0.434765  [38400/60000]\n",
      "loss: 0.594168  [44800/60000]\n",
      "loss: 0.554485  [51200/60000]\n",
      "loss: 0.405207  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.471555 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.288551  [    0/60000]\n",
      "loss: 0.435564  [ 6400/60000]\n",
      "loss: 0.272870  [12800/60000]\n",
      "loss: 0.458423  [19200/60000]\n",
      "loss: 0.396540  [25600/60000]\n",
      "loss: 0.430662  [32000/60000]\n",
      "loss: 0.421958  [38400/60000]\n",
      "loss: 0.582258  [44800/60000]\n",
      "loss: 0.541462  [51200/60000]\n",
      "loss: 0.399969  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.462362 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.278759  [    0/60000]\n",
      "loss: 0.424596  [ 6400/60000]\n",
      "loss: 0.265759  [12800/60000]\n",
      "loss: 0.448093  [19200/60000]\n",
      "loss: 0.384504  [25600/60000]\n",
      "loss: 0.423713  [32000/60000]\n",
      "loss: 0.410816  [38400/60000]\n",
      "loss: 0.569500  [44800/60000]\n",
      "loss: 0.530076  [51200/60000]\n",
      "loss: 0.395822  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.453967 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.270325  [    0/60000]\n",
      "loss: 0.413702  [ 6400/60000]\n",
      "loss: 0.260378  [12800/60000]\n",
      "loss: 0.438327  [19200/60000]\n",
      "loss: 0.373189  [25600/60000]\n",
      "loss: 0.416680  [32000/60000]\n",
      "loss: 0.400470  [38400/60000]\n",
      "loss: 0.556963  [44800/60000]\n",
      "loss: 0.519206  [51200/60000]\n",
      "loss: 0.391817  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.446812 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.263441  [    0/60000]\n",
      "loss: 0.404604  [ 6400/60000]\n",
      "loss: 0.254308  [12800/60000]\n",
      "loss: 0.428405  [19200/60000]\n",
      "loss: 0.364528  [25600/60000]\n",
      "loss: 0.410852  [32000/60000]\n",
      "loss: 0.391158  [38400/60000]\n",
      "loss: 0.544779  [44800/60000]\n",
      "loss: 0.510175  [51200/60000]\n",
      "loss: 0.388755  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.440154 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.257757  [    0/60000]\n",
      "loss: 0.396611  [ 6400/60000]\n",
      "loss: 0.249142  [12800/60000]\n",
      "loss: 0.418822  [19200/60000]\n",
      "loss: 0.356342  [25600/60000]\n",
      "loss: 0.403794  [32000/60000]\n",
      "loss: 0.381618  [38400/60000]\n",
      "loss: 0.532765  [44800/60000]\n",
      "loss: 0.502219  [51200/60000]\n",
      "loss: 0.386002  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.433680 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.251802  [    0/60000]\n",
      "loss: 0.388231  [ 6400/60000]\n",
      "loss: 0.243857  [12800/60000]\n",
      "loss: 0.410952  [19200/60000]\n",
      "loss: 0.350142  [25600/60000]\n",
      "loss: 0.397776  [32000/60000]\n",
      "loss: 0.373728  [38400/60000]\n",
      "loss: 0.521754  [44800/60000]\n",
      "loss: 0.492872  [51200/60000]\n",
      "loss: 0.383093  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.427523 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.246106  [    0/60000]\n",
      "loss: 0.381527  [ 6400/60000]\n",
      "loss: 0.239309  [12800/60000]\n",
      "loss: 0.403760  [19200/60000]\n",
      "loss: 0.344450  [25600/60000]\n",
      "loss: 0.392520  [32000/60000]\n",
      "loss: 0.366485  [38400/60000]\n",
      "loss: 0.512814  [44800/60000]\n",
      "loss: 0.484851  [51200/60000]\n",
      "loss: 0.380526  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.422265 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.239703  [    0/60000]\n",
      "loss: 0.374192  [ 6400/60000]\n",
      "loss: 0.235762  [12800/60000]\n",
      "loss: 0.395480  [19200/60000]\n",
      "loss: 0.338116  [25600/60000]\n",
      "loss: 0.387228  [32000/60000]\n",
      "loss: 0.360829  [38400/60000]\n",
      "loss: 0.503865  [44800/60000]\n",
      "loss: 0.477309  [51200/60000]\n",
      "loss: 0.377975  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.417076 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got accuracy 85.1% in 17 epochs\n",
      "Training with learning rate: 0.001 until reaching 85% accuracy\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300782  [    0/60000]\n",
      "loss: 2.289248  [ 6400/60000]\n",
      "loss: 2.266873  [12800/60000]\n",
      "loss: 2.264018  [19200/60000]\n",
      "loss: 2.245072  [25600/60000]\n",
      "loss: 2.217081  [32000/60000]\n",
      "loss: 2.225930  [38400/60000]\n",
      "loss: 2.189763  [44800/60000]\n",
      "loss: 2.179140  [51200/60000]\n",
      "loss: 2.156408  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 2.146119 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.154651  [    0/60000]\n",
      "loss: 2.146051  [ 6400/60000]\n",
      "loss: 2.083194  [12800/60000]\n",
      "loss: 2.101009  [19200/60000]\n",
      "loss: 2.054467  [25600/60000]\n",
      "loss: 1.986397  [32000/60000]\n",
      "loss: 2.019450  [38400/60000]\n",
      "loss: 1.934837  [44800/60000]\n",
      "loss: 1.928802  [51200/60000]\n",
      "loss: 1.869906  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.3%, Avg loss: 1.863098 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.897873  [    0/60000]\n",
      "loss: 1.872102  [ 6400/60000]\n",
      "loss: 1.746677  [12800/60000]\n",
      "loss: 1.787306  [19200/60000]\n",
      "loss: 1.695742  [25600/60000]\n",
      "loss: 1.635041  [32000/60000]\n",
      "loss: 1.662223  [38400/60000]\n",
      "loss: 1.560348  [44800/60000]\n",
      "loss: 1.582416  [51200/60000]\n",
      "loss: 1.488427  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 1.503461 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.569427  [    0/60000]\n",
      "loss: 1.542934  [ 6400/60000]\n",
      "loss: 1.387238  [12800/60000]\n",
      "loss: 1.460363  [19200/60000]\n",
      "loss: 1.358459  [25600/60000]\n",
      "loss: 1.338034  [32000/60000]\n",
      "loss: 1.357281  [38400/60000]\n",
      "loss: 1.280627  [44800/60000]\n",
      "loss: 1.314304  [51200/60000]\n",
      "loss: 1.220469  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.247432 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.319926  [    0/60000]\n",
      "loss: 1.311337  [ 6400/60000]\n",
      "loss: 1.140992  [12800/60000]\n",
      "loss: 1.246083  [19200/60000]\n",
      "loss: 1.132316  [25600/60000]\n",
      "loss: 1.144463  [32000/60000]\n",
      "loss: 1.166873  [38400/60000]\n",
      "loss: 1.106358  [44800/60000]\n",
      "loss: 1.144011  [51200/60000]\n",
      "loss: 1.059784  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.085583 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.150926  [    0/60000]\n",
      "loss: 1.163512  [ 6400/60000]\n",
      "loss: 0.976472  [12800/60000]\n",
      "loss: 1.108757  [19200/60000]\n",
      "loss: 0.992127  [25600/60000]\n",
      "loss: 1.013302  [32000/60000]\n",
      "loss: 1.048534  [38400/60000]\n",
      "loss: 0.994586  [44800/60000]\n",
      "loss: 1.032781  [51200/60000]\n",
      "loss: 0.957341  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.980242 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.032611  [    0/60000]\n",
      "loss: 1.066550  [ 6400/60000]\n",
      "loss: 0.863691  [12800/60000]\n",
      "loss: 1.016777  [19200/60000]\n",
      "loss: 0.904745  [25600/60000]\n",
      "loss: 0.920639  [32000/60000]\n",
      "loss: 0.970949  [38400/60000]\n",
      "loss: 0.921698  [44800/60000]\n",
      "loss: 0.955850  [51200/60000]\n",
      "loss: 0.888190  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.908279 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.945772  [    0/60000]\n",
      "loss: 0.998378  [ 6400/60000]\n",
      "loss: 0.782983  [12800/60000]\n",
      "loss: 0.951998  [19200/60000]\n",
      "loss: 0.847172  [25600/60000]\n",
      "loss: 0.852789  [32000/60000]\n",
      "loss: 0.916555  [38400/60000]\n",
      "loss: 0.872582  [44800/60000]\n",
      "loss: 0.900151  [51200/60000]\n",
      "loss: 0.838123  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.856362 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.879318  [    0/60000]\n",
      "loss: 0.946826  [ 6400/60000]\n",
      "loss: 0.722489  [12800/60000]\n",
      "loss: 0.903898  [19200/60000]\n",
      "loss: 0.806224  [25600/60000]\n",
      "loss: 0.801779  [32000/60000]\n",
      "loss: 0.875290  [38400/60000]\n",
      "loss: 0.837946  [44800/60000]\n",
      "loss: 0.858335  [51200/60000]\n",
      "loss: 0.799788  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 0.816963 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.826499  [    0/60000]\n",
      "loss: 0.905372  [ 6400/60000]\n",
      "loss: 0.675212  [12800/60000]\n",
      "loss: 0.867058  [19200/60000]\n",
      "loss: 0.775059  [25600/60000]\n",
      "loss: 0.762591  [32000/60000]\n",
      "loss: 0.841926  [38400/60000]\n",
      "loss: 0.812333  [44800/60000]\n",
      "loss: 0.825788  [51200/60000]\n",
      "loss: 0.769150  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 0.785643 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.782932  [    0/60000]\n",
      "loss: 0.870265  [ 6400/60000]\n",
      "loss: 0.636908  [12800/60000]\n",
      "loss: 0.837905  [19200/60000]\n",
      "loss: 0.749901  [25600/60000]\n",
      "loss: 0.731699  [32000/60000]\n",
      "loss: 0.813612  [38400/60000]\n",
      "loss: 0.792135  [44800/60000]\n",
      "loss: 0.799481  [51200/60000]\n",
      "loss: 0.743679  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.759661 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.745842  [    0/60000]\n",
      "loss: 0.839423  [ 6400/60000]\n",
      "loss: 0.604731  [12800/60000]\n",
      "loss: 0.814067  [19200/60000]\n",
      "loss: 0.728667  [25600/60000]\n",
      "loss: 0.706790  [32000/60000]\n",
      "loss: 0.788597  [38400/60000]\n",
      "loss: 0.775138  [44800/60000]\n",
      "loss: 0.777523  [51200/60000]\n",
      "loss: 0.721895  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.737298 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.713637  [    0/60000]\n",
      "loss: 0.811725  [ 6400/60000]\n",
      "loss: 0.577132  [12800/60000]\n",
      "loss: 0.793871  [19200/60000]\n",
      "loss: 0.710260  [25600/60000]\n",
      "loss: 0.686122  [32000/60000]\n",
      "loss: 0.766017  [38400/60000]\n",
      "loss: 0.760165  [44800/60000]\n",
      "loss: 0.758767  [51200/60000]\n",
      "loss: 0.702886  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.717518 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.685139  [    0/60000]\n",
      "loss: 0.786535  [ 6400/60000]\n",
      "loss: 0.553091  [12800/60000]\n",
      "loss: 0.776388  [19200/60000]\n",
      "loss: 0.693918  [25600/60000]\n",
      "loss: 0.668676  [32000/60000]\n",
      "loss: 0.745211  [38400/60000]\n",
      "loss: 0.746679  [44800/60000]\n",
      "loss: 0.742587  [51200/60000]\n",
      "loss: 0.686021  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.699700 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.659652  [    0/60000]\n",
      "loss: 0.763450  [ 6400/60000]\n",
      "loss: 0.531844  [12800/60000]\n",
      "loss: 0.760834  [19200/60000]\n",
      "loss: 0.679227  [25600/60000]\n",
      "loss: 0.653617  [32000/60000]\n",
      "loss: 0.725831  [38400/60000]\n",
      "loss: 0.734418  [44800/60000]\n",
      "loss: 0.728262  [51200/60000]\n",
      "loss: 0.670949  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.683450 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.636682  [    0/60000]\n",
      "loss: 0.742212  [ 6400/60000]\n",
      "loss: 0.512921  [12800/60000]\n",
      "loss: 0.746574  [19200/60000]\n",
      "loss: 0.666018  [25600/60000]\n",
      "loss: 0.640354  [32000/60000]\n",
      "loss: 0.707715  [38400/60000]\n",
      "loss: 0.723104  [44800/60000]\n",
      "loss: 0.715527  [51200/60000]\n",
      "loss: 0.657328  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.668519 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.615892  [    0/60000]\n",
      "loss: 0.722611  [ 6400/60000]\n",
      "loss: 0.495830  [12800/60000]\n",
      "loss: 0.733411  [19200/60000]\n",
      "loss: 0.654049  [25600/60000]\n",
      "loss: 0.628544  [32000/60000]\n",
      "loss: 0.690706  [38400/60000]\n",
      "loss: 0.712909  [44800/60000]\n",
      "loss: 0.704157  [51200/60000]\n",
      "loss: 0.644927  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.654752 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.596978  [    0/60000]\n",
      "loss: 0.704503  [ 6400/60000]\n",
      "loss: 0.480404  [12800/60000]\n",
      "loss: 0.721212  [19200/60000]\n",
      "loss: 0.643207  [25600/60000]\n",
      "loss: 0.618028  [32000/60000]\n",
      "loss: 0.674900  [38400/60000]\n",
      "loss: 0.703832  [44800/60000]\n",
      "loss: 0.694039  [51200/60000]\n",
      "loss: 0.633654  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.642046 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.579742  [    0/60000]\n",
      "loss: 0.687763  [ 6400/60000]\n",
      "loss: 0.466435  [12800/60000]\n",
      "loss: 0.709778  [19200/60000]\n",
      "loss: 0.633426  [25600/60000]\n",
      "loss: 0.608595  [32000/60000]\n",
      "loss: 0.660178  [38400/60000]\n",
      "loss: 0.695743  [44800/60000]\n",
      "loss: 0.685206  [51200/60000]\n",
      "loss: 0.623244  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.630313 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.564100  [    0/60000]\n",
      "loss: 0.672308  [ 6400/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     test_loss, accuracy \u001b[38;5;241m=\u001b[39m test(test_dataloader, model, loss_fn)\n\u001b[1;32m     18\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      5\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torchvision/datasets/mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:149\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be 2/3 dimensional. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpic\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m default_float_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# handle numpy array\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    152\u001b[0m         pic \u001b[38;5;241m=\u001b[39m pic[:, :, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train and test the model\n",
    "learning_rates = [1e-2, 1e-3]\n",
    "\n",
    "for rate in learning_rates:\n",
    "    print(f\"Training with learning rate: {rate} until reaching 85% accuracy\")\n",
    "    model = NeuralNetwork().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "        train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loss, accuracy = test(test_dataloader, model, loss_fn)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        if accuracy >= 0.85:\n",
    "            break\n",
    "        \n",
    "        epoch += 1\n",
    "\n",
    "    plt.plot(np.array(train_losses), 'r')\n",
    "    plt.plot(np.array(test_losses), 'b')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Got accuracy {(100*accuracy):>0.1f}% in {epoch + 1} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate: 1 until reaching 85% accuracy\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.313781  [    0/60000]\n",
      "loss: 2.286547  [ 6400/60000]\n",
      "loss: 2.312774  [12800/60000]\n",
      "loss: 2.304624  [19200/60000]\n",
      "loss: 2.280077  [25600/60000]\n",
      "loss: 2.339064  [32000/60000]\n",
      "loss: 3.201489  [38400/60000]\n",
      "loss: 1.692389  [44800/60000]\n",
      "loss: 1.734655  [51200/60000]\n",
      "loss: 3.663614  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 1.759443 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.784747  [    0/60000]\n",
      "loss: 1.698590  [ 6400/60000]\n",
      "loss: 1.800177  [12800/60000]\n",
      "loss: 2.255895  [19200/60000]\n",
      "loss: 2.003374  [25600/60000]\n",
      "loss: 1.745313  [32000/60000]\n",
      "loss: 1.663368  [38400/60000]\n",
      "loss: 1.609096  [44800/60000]\n",
      "loss: 1.719107  [51200/60000]\n",
      "loss: 1.698630  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.8%, Avg loss: 1.727040 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.861264  [    0/60000]\n",
      "loss: 1.686961  [ 6400/60000]\n",
      "loss: 1.739428  [12800/60000]\n",
      "loss: 1.788330  [19200/60000]\n",
      "loss: 1.660347  [25600/60000]\n",
      "loss: 3.081331  [32000/60000]\n",
      "loss: 1.710034  [38400/60000]\n",
      "loss: 1.675278  [44800/60000]\n",
      "loss: 1.726082  [51200/60000]\n",
      "loss: 1.681564  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 1.718273 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.773277  [    0/60000]\n",
      "loss: 1.688503  [ 6400/60000]\n",
      "loss: 1.744944  [12800/60000]\n",
      "loss: 1.790526  [19200/60000]\n",
      "loss: 1.594039  [25600/60000]\n",
      "loss: 1.729002  [32000/60000]\n",
      "loss: 1.750752  [38400/60000]\n",
      "loss: 1.675797  [44800/60000]\n",
      "loss: 1.680589  [51200/60000]\n",
      "loss: 1.681828  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 1.715889 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.781888  [    0/60000]\n",
      "loss: 1.785079  [ 6400/60000]\n",
      "loss: 1.732115  [12800/60000]\n",
      "loss: 1.736459  [19200/60000]\n",
      "loss: 1.654468  [25600/60000]\n",
      "loss: 1.725799  [32000/60000]\n",
      "loss: 1.848125  [38400/60000]\n",
      "loss: 1.673636  [44800/60000]\n",
      "loss: 1.783219  [51200/60000]\n",
      "loss: 1.679071  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 20.0%, Avg loss: 1.717964 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.783305  [    0/60000]\n",
      "loss: 1.690073  [ 6400/60000]\n",
      "loss: 1.733549  [12800/60000]\n",
      "loss: 1.736440  [19200/60000]\n",
      "loss: 1.648507  [25600/60000]\n",
      "loss: 1.673257  [32000/60000]\n",
      "loss: 1.649370  [38400/60000]\n",
      "loss: 1.671968  [44800/60000]\n",
      "loss: 1.677461  [51200/60000]\n",
      "loss: 1.679979  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 1.714318 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.776143  [    0/60000]\n",
      "loss: 1.687071  [ 6400/60000]\n",
      "loss: 1.731130  [12800/60000]\n",
      "loss: 1.794233  [19200/60000]\n",
      "loss: 1.639303  [25600/60000]\n",
      "loss: 1.725250  [32000/60000]\n",
      "loss: 2.299688  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305872 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305867 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305867 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330203  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305866 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330203  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305867 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305865 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330203  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305865 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330202  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305865 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312775  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281372  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300420  [51200/60000]\n",
      "loss: 2.330202  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305862 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 2.313044  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312774  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281353  [25600/60000]\n",
      "loss: 2.304957  [32000/60000]\n",
      "loss: 2.304671  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 1.746994  [51200/60000]\n",
      "loss: 1.697224  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 1.740852 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.713188  [    0/60000]\n",
      "loss: 1.689933  [ 6400/60000]\n",
      "loss: 1.752090  [12800/60000]\n",
      "loss: 1.752838  [19200/60000]\n",
      "loss: 1.671856  [25600/60000]\n",
      "loss: 1.737933  [32000/60000]\n",
      "loss: 1.656866  [38400/60000]\n",
      "loss: 1.675415  [44800/60000]\n",
      "loss: 1.481797  [51200/60000]\n",
      "loss: 1.680631  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 1.715230 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.690545  [    0/60000]\n",
      "loss: 1.682383  [ 6400/60000]\n",
      "loss: 1.739280  [12800/60000]\n",
      "loss: 1.720424  [19200/60000]\n",
      "loss: 1.657165  [25600/60000]\n",
      "loss: 1.791429  [32000/60000]\n",
      "loss: 1.652582  [38400/60000]\n",
      "loss: 1.680636  [44800/60000]\n",
      "loss: 1.679365  [51200/60000]\n",
      "loss: 1.679490  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.8%, Avg loss: 1.717212 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.690427  [    0/60000]\n",
      "loss: 1.685699  [ 6400/60000]\n",
      "loss: 1.735240  [12800/60000]\n",
      "loss: 1.741552  [19200/60000]\n",
      "loss: 1.653025  [25600/60000]\n",
      "loss: 1.727575  [32000/60000]\n",
      "loss: 1.651370  [38400/60000]\n",
      "loss: 1.675304  [44800/60000]\n",
      "loss: 1.675071  [51200/60000]\n",
      "loss: 1.678558  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 1.710829 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.687673  [    0/60000]\n",
      "loss: 1.683309  [ 6400/60000]\n",
      "loss: 1.731394  [12800/60000]\n",
      "loss: 1.736541  [19200/60000]\n",
      "loss: 1.641177  [25600/60000]\n",
      "loss: 1.811208  [32000/60000]\n",
      "loss: 1.650952  [38400/60000]\n",
      "loss: 2.347918  [44800/60000]\n",
      "loss: 2.247109  [51200/60000]\n",
      "loss: 2.330306  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305855 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2.313045  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312775  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281376  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305942  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305843 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312773  [12800/60000]\n",
      "loss: 2.304612  [19200/60000]\n",
      "loss: 2.281415  [25600/60000]\n",
      "loss: 2.237464  [32000/60000]\n",
      "loss: 2.314186  [38400/60000]\n",
      "loss: 1.772023  [44800/60000]\n",
      "loss: 1.707199  [51200/60000]\n",
      "loss: 1.693210  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 1.734198 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.819628  [    0/60000]\n",
      "loss: 1.691581  [ 6400/60000]\n",
      "loss: 1.749995  [12800/60000]\n",
      "loss: 1.789985  [19200/60000]\n",
      "loss: 1.651191  [25600/60000]\n",
      "loss: 1.737494  [32000/60000]\n",
      "loss: 1.653614  [38400/60000]\n",
      "loss: 1.675631  [44800/60000]\n",
      "loss: 1.682560  [51200/60000]\n",
      "loss: 1.681569  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.8%, Avg loss: 1.723444 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.766227  [    0/60000]\n",
      "loss: 1.686087  [ 6400/60000]\n",
      "loss: 1.748782  [12800/60000]\n",
      "loss: 1.741412  [19200/60000]\n",
      "loss: 1.649649  [25600/60000]\n",
      "loss: 1.729707  [32000/60000]\n",
      "loss: 1.653056  [38400/60000]\n",
      "loss: 1.671194  [44800/60000]\n",
      "loss: 1.678882  [51200/60000]\n",
      "loss: 1.679823  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.8%, Avg loss: 1.717740 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.771001  [    0/60000]\n",
      "loss: 1.684315  [ 6400/60000]\n",
      "loss: 1.733373  [12800/60000]\n",
      "loss: 1.798835  [19200/60000]\n",
      "loss: 1.652296  [25600/60000]\n",
      "loss: 1.727429  [32000/60000]\n",
      "loss: 1.651556  [38400/60000]\n",
      "loss: 1.671708  [44800/60000]\n",
      "loss: 1.677357  [51200/60000]\n",
      "loss: 1.679414  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 1.713102 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.780660  [    0/60000]\n",
      "loss: 1.686497  [ 6400/60000]\n",
      "loss: 1.731311  [12800/60000]\n",
      "loss: 1.735765  [19200/60000]\n",
      "loss: 1.652294  [25600/60000]\n",
      "loss: 1.725155  [32000/60000]\n",
      "loss: 1.750668  [38400/60000]\n",
      "loss: 1.672831  [44800/60000]\n",
      "loss: 1.676866  [51200/60000]\n",
      "loss: 1.678608  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 1.709688 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.690433  [    0/60000]\n",
      "loss: 1.683717  [ 6400/60000]\n",
      "loss: 1.730378  [12800/60000]\n",
      "loss: 1.736048  [19200/60000]\n",
      "loss: 1.643013  [25600/60000]\n",
      "loss: 1.725917  [32000/60000]\n",
      "loss: 1.649307  [38400/60000]\n",
      "loss: 1.671712  [44800/60000]\n",
      "loss: 1.676906  [51200/60000]\n",
      "loss: 1.679131  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 20.0%, Avg loss: 1.709412 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.690593  [    0/60000]\n",
      "loss: 1.690896  [ 6400/60000]\n",
      "loss: 1.729394  [12800/60000]\n",
      "loss: 5.378680  [19200/60000]\n",
      "loss: 2.281349  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305941  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305942  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305942  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305942  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305942  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305942  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305943  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305942  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 2.313044  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305942  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305942  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305941  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305939  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305939  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305938  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305936  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305934  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305933  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305844 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 2.313041  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305933  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305930  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305928  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305926  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305924  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281362  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305925  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305923  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305922  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305919  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305861 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 2.313045  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305920  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330200  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305867 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305917  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330198  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305858 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 2.313044  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305917  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330198  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305844 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 2.313040  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305917  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330197  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305863 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305916  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330196  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305884 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305915  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305897 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330196  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305859 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305880 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305894 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305903 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305910 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305915 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305920 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305924 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305929 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305915  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305864 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305915  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305883 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305896 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305906 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305915 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305922 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305928 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305934 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305940 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305947 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305953 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305915  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305960 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305915  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305967 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305915  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305974 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305916  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305938 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305916  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305952 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305916  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305964 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305915  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305854 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 2.313044  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305917  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305887 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305916  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305911 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305916  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305929 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305916  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305943 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305916  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305955 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305916  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305965 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305916  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305975 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305916  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305984 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305917  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305993 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304622  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305915  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305853 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305914  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305855 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312774  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281377  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305915  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305819 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312772  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305912  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305834 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 2.313045  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312772  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305911  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305796 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312769  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305909  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300250  [51200/60000]\n",
      "loss: 2.330194  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305716 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312768  [12800/60000]\n",
      "loss: 2.304635  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.313318  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305944  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306796  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304950  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n",
      "loss: 2.304621  [19200/60000]\n",
      "loss: 2.281378  [25600/60000]\n",
      "loss: 2.304951  [32000/60000]\n",
      "loss: 2.305945  [38400/60000]\n",
      "loss: 2.288610  [44800/60000]\n",
      "loss: 2.300421  [51200/60000]\n",
      "loss: 2.330204  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305845 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 2.313046  [    0/60000]\n",
      "loss: 2.306795  [ 6400/60000]\n",
      "loss: 2.312776  [12800/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     test_loss, accuracy \u001b[38;5;241m=\u001b[39m test(test_dataloader, model, loss_fn)\n\u001b[1;32m     15\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      5\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torchvision/datasets/mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:139\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_tensor\u001b[39m(pic: Union[PILImage, np\u001b[38;5;241m.\u001b[39mndarray]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    This function does not support torchscript.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_tracing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    140\u001b[0m         _log_api_usage_once(to_tensor)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (F_pil\u001b[38;5;241m.\u001b[39m_is_pil_image(pic) \u001b[38;5;129;01mor\u001b[39;00m _is_numpy(pic)):\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torch/jit/_trace.py:1139\u001b[0m, in \u001b[0;36mis_tracing\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_tracing\u001b[39m():\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a boolean value.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[38;5;124;03m    Returns ``True`` in tracing (if a function is called during the\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;124;03m    tracing of code with ``torch.jit.trace``) and ``False`` otherwise.\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_scripting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_is_tracing()\n",
      "File \u001b[0;32m~/Uni/COMP-SCI-7315-Computer-Vision/.venv/lib/python3.10/site-packages/torch/_jit_internal.py:1120\u001b[0m, in \u001b[0;36mis_scripting\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m7\u001b[39m):\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroadcastingList\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m BroadcastingList1\n\u001b[0;32m-> 1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_scripting\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03m    Function that returns True when in compilation and False otherwise. This\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;124;03m    is useful especially with the @unused decorator to leave code in your\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;124;03m              return unsupported_linear_op(x)\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rate = 1\n",
    "print(f\"Training with learning rate: {rate} until reaching 85% accuracy\")\n",
    "model = NeuralNetwork().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "epoch = 0\n",
    "while True:\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loss, accuracy = test(test_dataloader, model, loss_fn)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    if accuracy >= 0.85:\n",
    "        break\n",
    "    \n",
    "    epoch += 1\n",
    "\n",
    "plt.plot(np.array(train_losses), 'r')\n",
    "plt.plot(np.array(test_losses), 'b')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Got accuracy {(100*accuracy):>0.1f}% in {epoch + 1} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Training for 10 epochs with learning rate: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300169  [    0/60000]\n",
      "loss: 2.280763  [ 6400/60000]\n",
      "loss: 2.249119  [12800/60000]\n",
      "loss: 2.246641  [19200/60000]\n",
      "loss: 2.218433  [25600/60000]\n",
      "loss: 2.170005  [32000/60000]\n",
      "loss: 2.190795  [38400/60000]\n",
      "loss: 2.140498  [44800/60000]\n",
      "loss: 2.136901  [51200/60000]\n",
      "loss: 2.084907  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 2.079782 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.095179  [    0/60000]\n",
      "loss: 2.079972  [ 6400/60000]\n",
      "loss: 1.995495  [12800/60000]\n",
      "loss: 2.023554  [19200/60000]\n",
      "loss: 1.935881  [25600/60000]\n",
      "loss: 1.860414  [32000/60000]\n",
      "loss: 1.901538  [38400/60000]\n",
      "loss: 1.801681  [44800/60000]\n",
      "loss: 1.810653  [51200/60000]\n",
      "loss: 1.712867  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 1.718643 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.761845  [    0/60000]\n",
      "loss: 1.730359  [ 6400/60000]\n",
      "loss: 1.588402  [12800/60000]\n",
      "loss: 1.652149  [19200/60000]\n",
      "loss: 1.514325  [25600/60000]\n",
      "loss: 1.478442  [32000/60000]\n",
      "loss: 1.510420  [38400/60000]\n",
      "loss: 1.419378  [44800/60000]\n",
      "loss: 1.444338  [51200/60000]\n",
      "loss: 1.335189  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.360135 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.428474  [    0/60000]\n",
      "loss: 1.407571  [ 6400/60000]\n",
      "loss: 1.243573  [12800/60000]\n",
      "loss: 1.345297  [19200/60000]\n",
      "loss: 1.205789  [25600/60000]\n",
      "loss: 1.210771  [32000/60000]\n",
      "loss: 1.242109  [38400/60000]\n",
      "loss: 1.172745  [44800/60000]\n",
      "loss: 1.204004  [51200/60000]\n",
      "loss: 1.111565  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.136597 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.203333  [    0/60000]\n",
      "loss: 1.205174  [ 6400/60000]\n",
      "loss: 1.023753  [12800/60000]\n",
      "loss: 1.162395  [19200/60000]\n",
      "loss: 1.020628  [25600/60000]\n",
      "loss: 1.040952  [32000/60000]\n",
      "loss: 1.085021  [38400/60000]\n",
      "loss: 1.024424  [44800/60000]\n",
      "loss: 1.058077  [51200/60000]\n",
      "loss: 0.982093  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 1.001288 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.055739  [    0/60000]\n",
      "loss: 1.081764  [ 6400/60000]\n",
      "loss: 0.881748  [12800/60000]\n",
      "loss: 1.048316  [19200/60000]\n",
      "loss: 0.910431  [25600/60000]\n",
      "loss: 0.928892  [32000/60000]\n",
      "loss: 0.988613  [38400/60000]\n",
      "loss: 0.933109  [44800/60000]\n",
      "loss: 0.963495  [51200/60000]\n",
      "loss: 0.900600  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.914458 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.953298  [    0/60000]\n",
      "loss: 1.001358  [ 6400/60000]\n",
      "loss: 0.785270  [12800/60000]\n",
      "loss: 0.972531  [19200/60000]\n",
      "loss: 0.841044  [25600/60000]\n",
      "loss: 0.851333  [32000/60000]\n",
      "loss: 0.924555  [38400/60000]\n",
      "loss: 0.874757  [44800/60000]\n",
      "loss: 0.898243  [51200/60000]\n",
      "loss: 0.844754  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.854847 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.878132  [    0/60000]\n",
      "loss: 0.944141  [ 6400/60000]\n",
      "loss: 0.716073  [12800/60000]\n",
      "loss: 0.918976  [19200/60000]\n",
      "loss: 0.793692  [25600/60000]\n",
      "loss: 0.795591  [32000/60000]\n",
      "loss: 0.878148  [38400/60000]\n",
      "loss: 0.835444  [44800/60000]\n",
      "loss: 0.850932  [51200/60000]\n",
      "loss: 0.803382  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.811065 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.819916  [    0/60000]\n",
      "loss: 0.899678  [ 6400/60000]\n",
      "loss: 0.663806  [12800/60000]\n",
      "loss: 0.878843  [19200/60000]\n",
      "loss: 0.758648  [25600/60000]\n",
      "loss: 0.754066  [32000/60000]\n",
      "loss: 0.841713  [38400/60000]\n",
      "loss: 0.807087  [44800/60000]\n",
      "loss: 0.814708  [51200/60000]\n",
      "loss: 0.770843  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.776864 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.772660  [    0/60000]\n",
      "loss: 0.862526  [ 6400/60000]\n",
      "loss: 0.622364  [12800/60000]\n",
      "loss: 0.847405  [19200/60000]\n",
      "loss: 0.730980  [25600/60000]\n",
      "loss: 0.722173  [32000/60000]\n",
      "loss: 0.811085  [38400/60000]\n",
      "loss: 0.785170  [44800/60000]\n",
      "loss: 0.785485  [51200/60000]\n",
      "loss: 0.743677  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.748713 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.5\n",
    "\n",
    "# WIDE\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 10)\n",
    "       )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "###Define the loss function and the optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "#Train and test the model\n",
    "epochs = 10\n",
    "rate = 1e-3\n",
    "\n",
    "print(f\"Training for {epochs} epochs with learning rate: {rate}\")\n",
    "model = NeuralNetwork().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loss, _ = test(test_dataloader, model, loss_fn)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "plt.plot(np.array(train_losses), 'r')\n",
    "plt.plot(np.array(test_losses), 'b')\n",
    "plt.show()\n",
    "\n",
    "print(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Training for 10 epochs with learning rate: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302104  [    0/60000]\n",
      "loss: 2.301270  [ 6400/60000]\n",
      "loss: 2.301379  [12800/60000]\n",
      "loss: 2.301877  [19200/60000]\n",
      "loss: 2.300066  [25600/60000]\n",
      "loss: 2.302263  [32000/60000]\n",
      "loss: 2.299258  [38400/60000]\n",
      "loss: 2.301517  [44800/60000]\n",
      "loss: 2.297601  [51200/60000]\n",
      "loss: 2.296129  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 2.297879 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.296856  [    0/60000]\n",
      "loss: 2.296398  [ 6400/60000]\n",
      "loss: 2.295116  [12800/60000]\n",
      "loss: 2.297185  [19200/60000]\n",
      "loss: 2.294525  [25600/60000]\n",
      "loss: 2.295180  [32000/60000]\n",
      "loss: 2.294098  [38400/60000]\n",
      "loss: 2.294504  [44800/60000]\n",
      "loss: 2.292291  [51200/60000]\n",
      "loss: 2.290026  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 30.8%, Avg loss: 2.291435 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.290810  [    0/60000]\n",
      "loss: 2.290608  [ 6400/60000]\n",
      "loss: 2.287609  [12800/60000]\n",
      "loss: 2.291313  [19200/60000]\n",
      "loss: 2.287424  [25600/60000]\n",
      "loss: 2.286683  [32000/60000]\n",
      "loss: 2.287200  [38400/60000]\n",
      "loss: 2.285554  [44800/60000]\n",
      "loss: 2.284735  [51200/60000]\n",
      "loss: 2.281794  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 2.282761 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.282509  [    0/60000]\n",
      "loss: 2.282481  [ 6400/60000]\n",
      "loss: 2.277155  [12800/60000]\n",
      "loss: 2.282893  [19200/60000]\n",
      "loss: 2.277157  [25600/60000]\n",
      "loss: 2.274563  [32000/60000]\n",
      "loss: 2.276906  [38400/60000]\n",
      "loss: 2.272656  [44800/60000]\n",
      "loss: 2.273081  [51200/60000]\n",
      "loss: 2.269095  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 2.269472 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.269843  [    0/60000]\n",
      "loss: 2.269765  [ 6400/60000]\n",
      "loss: 2.260956  [12800/60000]\n",
      "loss: 2.269193  [19200/60000]\n",
      "loss: 2.260641  [25600/60000]\n",
      "loss: 2.255134  [32000/60000]\n",
      "loss: 2.259715  [38400/60000]\n",
      "loss: 2.251264  [44800/60000]\n",
      "loss: 2.253011  [51200/60000]\n",
      "loss: 2.246873  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.3%, Avg loss: 2.246594 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.248189  [    0/60000]\n",
      "loss: 2.247501  [ 6400/60000]\n",
      "loss: 2.232399  [12800/60000]\n",
      "loss: 2.244250  [19200/60000]\n",
      "loss: 2.229999  [25600/60000]\n",
      "loss: 2.219651  [32000/60000]\n",
      "loss: 2.226722  [38400/60000]\n",
      "loss: 2.209998  [44800/60000]\n",
      "loss: 2.212491  [51200/60000]\n",
      "loss: 2.201455  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 2.200220 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.204453  [    0/60000]\n",
      "loss: 2.200616  [ 6400/60000]\n",
      "loss: 2.172224  [12800/60000]\n",
      "loss: 2.190154  [19200/60000]\n",
      "loss: 2.162233  [25600/60000]\n",
      "loss: 2.140039  [32000/60000]\n",
      "loss: 2.151232  [38400/60000]\n",
      "loss: 2.113678  [44800/60000]\n",
      "loss: 2.115737  [51200/60000]\n",
      "loss: 2.091421  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 2.088060 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.098875  [    0/60000]\n",
      "loss: 2.084215  [ 6400/60000]\n",
      "loss: 2.023508  [12800/60000]\n",
      "loss: 2.052330  [19200/60000]\n",
      "loss: 1.988691  [25600/60000]\n",
      "loss: 1.942864  [32000/60000]\n",
      "loss: 1.962640  [38400/60000]\n",
      "loss: 1.880358  [44800/60000]\n",
      "loss: 1.893813  [51200/60000]\n",
      "loss: 1.833021  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 1.831489 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.866929  [    0/60000]\n",
      "loss: 1.828448  [ 6400/60000]\n",
      "loss: 1.721110  [12800/60000]\n",
      "loss: 1.766132  [19200/60000]\n",
      "loss: 1.669290  [25600/60000]\n",
      "loss: 1.630153  [32000/60000]\n",
      "loss: 1.653787  [38400/60000]\n",
      "loss: 1.563390  [44800/60000]\n",
      "loss: 1.606851  [51200/60000]\n",
      "loss: 1.514027  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 1.522539 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.597429  [    0/60000]\n",
      "loss: 1.550254  [ 6400/60000]\n",
      "loss: 1.419632  [12800/60000]\n",
      "loss: 1.472009  [19200/60000]\n",
      "loss: 1.406686  [25600/60000]\n",
      "loss: 1.396622  [32000/60000]\n",
      "loss: 1.402651  [38400/60000]\n",
      "loss: 1.341816  [44800/60000]\n",
      "loss: 1.379578  [51200/60000]\n",
      "loss: 1.298862  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.7%, Avg loss: 1.306444 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.5\n",
    "\n",
    "# DEEP\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "       )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "###Define the loss function and the optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "#Train and test the model\n",
    "epochs = 10\n",
    "rate = 1e-3\n",
    "\n",
    "print(f\"Training for {epochs} epochs with learning rate: {rate}\")\n",
    "model = NeuralNetwork().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loss, _ = test(test_dataloader, model, loss_fn)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "plt.plot(np.array(train_losses), 'r')\n",
    "plt.plot(np.array(test_losses), 'b')\n",
    "plt.show()\n",
    "\n",
    "print(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.3151e-05, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 1.6\n",
    "# TODO: Should this be happening during the training process?\n",
    "\n",
    "# TODO Where does the input come from?\n",
    "input = torch.randn(1, 1, 28, 28)\n",
    "output = model(input.to(device))\n",
    "\n",
    "# TODO: Where do the targets come from?\n",
    "target = torch.randn(10).to(device)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "\n",
    "loss = loss_fn(output, target)\n",
    "loss.backward()\n",
    "\n",
    "# TODO: Update model to be CNN? Nope this is question 7 actually\n",
    "# TODO: Specify layers individually on the model instead of in ReLU stack?\n",
    "print(model.linear_relu_stack[0].weight.grad.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 89 %\n"
     ]
    }
   ],
   "source": [
    "# 1.7\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        #self.linear_relu_stack = nn.Sequential(\n",
    "        #      nn.Linear(32*32*3, 512),\n",
    "        #      nn.ReLU(),\n",
    "        #      nn.Linear(512, 512),\n",
    "        #      nn.ReLU(),\n",
    "        #      nn.Linear(512, 10)\n",
    "        #) \n",
    "        self.conv1 = nn.Conv2d(1, 12, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(12, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #x = self.flatten(x)\n",
    "        #x = self.linear_relu_stack(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.requires_grad_()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight: 0.0174\n",
      "conv1.bias: 0.0239\n",
      "conv2.weight: 0.0130\n",
      "conv2.bias: 0.0100\n",
      "fc1.weight: 0.0059\n",
      "fc1.bias: 0.0027\n",
      "fc2.weight: 0.0059\n",
      "fc2.bias: 0.0041\n",
      "fc3.weight: 0.0091\n",
      "fc3.bias: 0.0049\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_mean_gradients(model):\n",
    "    mean_grads = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            mean_grads[name] = param.grad.abs().mean().item()\n",
    "    return mean_grads\n",
    "\n",
    "mean_grads = compute_mean_gradients(net)\n",
    "for name, mean_grad in mean_grads.items():\n",
    "    print(f'{name}: {mean_grad:.4f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
